{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"asterius is a Haskell to WebAssembly compiler. The project is in alpha stage and in active development. Sponsors Asterius is maintained by Tweag I/O . Have questions? Need help? Tweet at @tweagio .","title":"Home"},{"location":"#sponsors","text":"Asterius is maintained by Tweag I/O . Have questions? Need help? Tweet at @tweagio .","title":"Sponsors"},{"location":"ahc-link/","text":"Using ahc-dist / ahc-link ahc-link is the frontend program of Asterius. It taks a Haskell Main module and optionally an ES6 \"entry\" module as input, then emits a .wasm WebAssembly binary module and companion JavaScript, which can be run in Node.js or browser environments. ahc-dist works similarly, except it takes the \"executable\" file generated from ahc (either directly by calling ahc , or indirectly by using cabal ) as input. Most command-line arguments are the same as ahc-link , except ahc-link takes --input-hs , while ahc-dist takes --input-exe . The options are described in full details here. Basic input/output options --input-hs ARG The Haskell Main module's file path. This option doesn't have a default and is mandatory; all others are optional. This works only for ahc-link . --input-exe ARG The \"executable\" file path. This works only for ahc-dist , and is also mandatory. --input-mjs ARG The ES6 \"entry\" module's file path. If not specified, the default entry module initializes an Asterius instance and calls Main.main , and upon normal completion, prints the standard output via console.log . It's possible to override the default behavior by specifying your own entry module. First, you need two imports (the relevant files are auto-generated and don't exist yet): import { module } from \"./xx.wasm.mjs\"; import { newInstance } from \"./xx.lib.mjs\"; Assuming xx.hs is the input Haskell Main module. Now, module is a Promise which resolves to a WebAssembly.Module . It's stateless and supports structured cloning, so it's possible to reuse it by send it to Worker s, store it in IndexedDB, etc. To avoid unnecessary compilation when reusing it, you need the dynamic import() for xx.wasm.mjs instead. newInstance is an async function which takes the WebAssembly.Module and resolves to an Asterius instance. An Asterius instance is a super-set of a WebAssembly.Instance and contains stateful fields to support running Haskell code. You can take a look at the manually written entry modules in asterius/test to get some idea on the capabilities of such an instance. --output-directory ARG Specifies the output directory. Defaults to the same directory of --input-hs . --output-prefix ARG Specifies the prefix of the output files. Defaults to the base filename of --input-hs , so for xx.hs , we generate xx.wasm , xx.lib.mjs , etc. Common options for controlling outputs --tail-calls Enable the WebAssembly tail call opcodes in output binary. This requires Node.js/Chromium to be built with a fairly recent revision of V8, and called with the --experimental-wasm-return-call flag. Doesn't work with the binaryen backend yet. See the \"Using experimental WebAssembly features\" section for more details. --ghc-option ARG Specify additional ghc options. The {-# OPTIONS_GHC #-} pragma also works. --browser Indicates the output code is to be run in a browser environment. By default, the output code is intended to be run by Node.js instead. --bundle Instead of copying the runtime .mjs modules to the target directory, generate a self-contained xx.js script, and running xx.js has the same effect as running the entry module. Only works for browser targets. --bundle is supported by Parcel under the hood and performs minification on the bundled JavaScript file. It's likely beneficial since it reduces total size of scripts and doesn't require multiple requests for fetching them. More advanced options for hackers --run Runs the output code using node . Ignored for browser targets. --binaryen Use the binaryen backend for generating .wasm files. Also note that with the binaryen backend, we use the binaryen relooper instead of our own relooper, which at the moment may give better runtime performance. If you observe any different runtime behavior of output code when this option is on, it's a bug! --debug Switch on the debug mode. Emits a ton of event logs suitable for piping to grep (or just leave it on the screen in case you'd like some hypnosis) --full-sym-table Contain the full symbol table into xx.lib.mjs . Automatically implied by --debug . --no-gc-sections Do not run dead code elimination. Options affecting the linker --export-function ARG Use this when you foreign export javascript anything. Otherwise the dead code elimination performed by the linker will surely exclude that code from the output WebAssembly module if it's not transitively used by Main.main ! --extra-root-symbol ARG Use this to specify a symbol to be added to the \"root symbol set\". Works similar to --export-function , but the argument is not a Haskell function name, but a symbol name directly. Additional outputs for the curious --output-link-report Output a \"link report\" text file containing internal linker stats. --output-ir Output wasm IRs of compiled Haskell modules and the resulting module. The IRs aren't intended to be consumed by external tools like binaryen/wabt.","title":"Using ahc-dist/ahc-link"},{"location":"ahc-link/#using-ahc-distahc-link","text":"ahc-link is the frontend program of Asterius. It taks a Haskell Main module and optionally an ES6 \"entry\" module as input, then emits a .wasm WebAssembly binary module and companion JavaScript, which can be run in Node.js or browser environments. ahc-dist works similarly, except it takes the \"executable\" file generated from ahc (either directly by calling ahc , or indirectly by using cabal ) as input. Most command-line arguments are the same as ahc-link , except ahc-link takes --input-hs , while ahc-dist takes --input-exe . The options are described in full details here.","title":"Using ahc-dist/ahc-link"},{"location":"ahc-link/#basic-inputoutput-options","text":"","title":"Basic input/output options"},{"location":"ahc-link/#-input-hs-arg","text":"The Haskell Main module's file path. This option doesn't have a default and is mandatory; all others are optional. This works only for ahc-link .","title":"--input-hs ARG"},{"location":"ahc-link/#-input-exe-arg","text":"The \"executable\" file path. This works only for ahc-dist , and is also mandatory.","title":"--input-exe ARG"},{"location":"ahc-link/#-input-mjs-arg","text":"The ES6 \"entry\" module's file path. If not specified, the default entry module initializes an Asterius instance and calls Main.main , and upon normal completion, prints the standard output via console.log . It's possible to override the default behavior by specifying your own entry module. First, you need two imports (the relevant files are auto-generated and don't exist yet): import { module } from \"./xx.wasm.mjs\"; import { newInstance } from \"./xx.lib.mjs\"; Assuming xx.hs is the input Haskell Main module. Now, module is a Promise which resolves to a WebAssembly.Module . It's stateless and supports structured cloning, so it's possible to reuse it by send it to Worker s, store it in IndexedDB, etc. To avoid unnecessary compilation when reusing it, you need the dynamic import() for xx.wasm.mjs instead. newInstance is an async function which takes the WebAssembly.Module and resolves to an Asterius instance. An Asterius instance is a super-set of a WebAssembly.Instance and contains stateful fields to support running Haskell code. You can take a look at the manually written entry modules in asterius/test to get some idea on the capabilities of such an instance.","title":"--input-mjs ARG"},{"location":"ahc-link/#-output-directory-arg","text":"Specifies the output directory. Defaults to the same directory of --input-hs .","title":"--output-directory ARG"},{"location":"ahc-link/#-output-prefix-arg","text":"Specifies the prefix of the output files. Defaults to the base filename of --input-hs , so for xx.hs , we generate xx.wasm , xx.lib.mjs , etc.","title":"--output-prefix ARG"},{"location":"ahc-link/#common-options-for-controlling-outputs","text":"","title":"Common options for controlling outputs"},{"location":"ahc-link/#-tail-calls","text":"Enable the WebAssembly tail call opcodes in output binary. This requires Node.js/Chromium to be built with a fairly recent revision of V8, and called with the --experimental-wasm-return-call flag. Doesn't work with the binaryen backend yet. See the \"Using experimental WebAssembly features\" section for more details.","title":"--tail-calls"},{"location":"ahc-link/#-ghc-option-arg","text":"Specify additional ghc options. The {-# OPTIONS_GHC #-} pragma also works.","title":"--ghc-option ARG"},{"location":"ahc-link/#-browser","text":"Indicates the output code is to be run in a browser environment. By default, the output code is intended to be run by Node.js instead.","title":"--browser"},{"location":"ahc-link/#-bundle","text":"Instead of copying the runtime .mjs modules to the target directory, generate a self-contained xx.js script, and running xx.js has the same effect as running the entry module. Only works for browser targets. --bundle is supported by Parcel under the hood and performs minification on the bundled JavaScript file. It's likely beneficial since it reduces total size of scripts and doesn't require multiple requests for fetching them.","title":"--bundle"},{"location":"ahc-link/#more-advanced-options-for-hackers","text":"","title":"More advanced options for hackers"},{"location":"ahc-link/#-run","text":"Runs the output code using node . Ignored for browser targets.","title":"--run"},{"location":"ahc-link/#-binaryen","text":"Use the binaryen backend for generating .wasm files. Also note that with the binaryen backend, we use the binaryen relooper instead of our own relooper, which at the moment may give better runtime performance. If you observe any different runtime behavior of output code when this option is on, it's a bug!","title":"--binaryen"},{"location":"ahc-link/#-debug","text":"Switch on the debug mode. Emits a ton of event logs suitable for piping to grep (or just leave it on the screen in case you'd like some hypnosis)","title":"--debug"},{"location":"ahc-link/#-full-sym-table","text":"Contain the full symbol table into xx.lib.mjs . Automatically implied by --debug .","title":"--full-sym-table"},{"location":"ahc-link/#-no-gc-sections","text":"Do not run dead code elimination.","title":"--no-gc-sections"},{"location":"ahc-link/#options-affecting-the-linker","text":"","title":"Options affecting the linker"},{"location":"ahc-link/#-export-function-arg","text":"Use this when you foreign export javascript anything. Otherwise the dead code elimination performed by the linker will surely exclude that code from the output WebAssembly module if it's not transitively used by Main.main !","title":"--export-function ARG"},{"location":"ahc-link/#-extra-root-symbol-arg","text":"Use this to specify a symbol to be added to the \"root symbol set\". Works similar to --export-function , but the argument is not a Haskell function name, but a symbol name directly.","title":"--extra-root-symbol ARG"},{"location":"ahc-link/#additional-outputs-for-the-curious","text":"","title":"Additional outputs for the curious"},{"location":"ahc-link/#-output-link-report","text":"Output a \"link report\" text file containing internal linker stats.","title":"--output-link-report"},{"location":"ahc-link/#-output-ir","text":"Output wasm IRs of compiled Haskell modules and the resulting module. The IRs aren't intended to be consumed by external tools like binaryen/wabt.","title":"--output-ir"},{"location":"architecture/","text":"High-level architecture The asterius project is hosted at GitHub . The monorepo contains several packages: asterius . This is the central package of the asterius compiler. binaryen . It contains the latest source code of the C++ library binaryen in tree, and provides complete raw bindings to its C API . ghc-toolkit . It provides a framework for implementing Haskell-to-X compilers by retrieving ghc 's various types of in-memory intermediate representations. It also contains the latest source code of ghc-prim / integer-gmp / integer-simple / base in tree. wasm-toolkit . It implements the WebAssembly AST and binary encoder/decoder in Haskell, and is now the default backend for generating WebAssembly binary code. The asterius package provides an ahc executable which is a drop-in replacement of ghc to be used with Setup configure . ahc redirects all arguments to the real ghc most of the time, but when it's invoked with the --make major mode, it invokes ghc with its frontend plugin. This is inspired by Edward Yang's How to integrate GHC API programs with Cabal . Based on ghc-toolkit , asterius implements a ghc frontend plugin which translates Cmm to binaryen IR. The serialized binaryen IR can then be loaded and linked to a WebAssembly binary (not implemented yet). The normal compilation pipeline which generates native machine code is not affected. About \"booting\" In order for asterius to support non-trivial Haskell programs (that is, at least most things in Prelude ), it needs to run the compilation process for base and its dependent packages. This process is known as \"booting\". The asterius package provides an ahc-boot test suite which tests booting by compiling the wired-in packages provided by ghc-toolkit and using ahc to replace ghc when configuring. This is inspired by Joachim Breitner's veggies .","title":"Project architecture"},{"location":"architecture/#high-level-architecture","text":"The asterius project is hosted at GitHub . The monorepo contains several packages: asterius . This is the central package of the asterius compiler. binaryen . It contains the latest source code of the C++ library binaryen in tree, and provides complete raw bindings to its C API . ghc-toolkit . It provides a framework for implementing Haskell-to-X compilers by retrieving ghc 's various types of in-memory intermediate representations. It also contains the latest source code of ghc-prim / integer-gmp / integer-simple / base in tree. wasm-toolkit . It implements the WebAssembly AST and binary encoder/decoder in Haskell, and is now the default backend for generating WebAssembly binary code. The asterius package provides an ahc executable which is a drop-in replacement of ghc to be used with Setup configure . ahc redirects all arguments to the real ghc most of the time, but when it's invoked with the --make major mode, it invokes ghc with its frontend plugin. This is inspired by Edward Yang's How to integrate GHC API programs with Cabal . Based on ghc-toolkit , asterius implements a ghc frontend plugin which translates Cmm to binaryen IR. The serialized binaryen IR can then be loaded and linked to a WebAssembly binary (not implemented yet). The normal compilation pipeline which generates native machine code is not affected.","title":"High-level architecture"},{"location":"architecture/#about-booting","text":"In order for asterius to support non-trivial Haskell programs (that is, at least most things in Prelude ), it needs to run the compilation process for base and its dependent packages. This process is known as \"booting\". The asterius package provides an ahc-boot test suite which tests booting by compiling the wired-in packages provided by ghc-toolkit and using ahc to replace ghc when configuring. This is inspired by Joachim Breitner's veggies .","title":"About \"booting\""},{"location":"building/","text":"Building guide asterius is tested on Linux x64. Windows/macOS x64 may also work. A pre-built Docker image is provided for your convenience. Using a pre-built Docker image We build and test Docker images on CircleCI. They are pushed to terrorjack/asterius , the tags are git revisions. terrorjack/asterius:latest correspond to latest revision on master . Put input program in a directory (e.g. ~/mirror ), then map the directory to a Docker volume: terrorjack@ubuntu:~$ docker run -it -v ~/mirror:/mirror terrorjack/asterius root@76bcb511663d:~# cd /mirror root@76bcb511663d:/mirror# ahc-link --help ... Building custom ghc asterius requires a forked ghc which can be found here . We are looking forward to building asterius with vanilla ghc-head in the long run, but at the moment, we use our own ghc fork so it's easy to test radical changes on ghc itself. The building guide of ghc can be found here . On Linux/macOS, a prebuilt ghc tarball is provided. It's already included in stack.yaml . Note that the Windows bindist does not provide prof libs/haddock (due to AppVeyor build time restriction). Extra dependencies Besides the custom ghc , these dependencies are also required: cmake / make / g++ : For building in-tree binaryen autoconf : For booting ghc-prim / base nodejs : For running tests. Ensure the latest version is used, since we rely on some recent V8 experimental features (e.g. BigInt support) stack : Someday cabal may also work, no specific obstacles anyway. Building asterius stack build asterius . That's it. Set MAKEFLAGS=-j8 to pass flags to make for parallel building of binaryen . After the dust settles, run stack exec ahc-boot to perform booting. Set the ASTERIUS_DEBUG environment variable to make ahc-boot print IRs to text files which are useful when debugging compiled code of standard libraries. Be aware that this flag slows down the booting process significantly!","title":"Building guide"},{"location":"building/#building-guide","text":"asterius is tested on Linux x64. Windows/macOS x64 may also work. A pre-built Docker image is provided for your convenience.","title":"Building guide"},{"location":"building/#using-a-pre-built-docker-image","text":"We build and test Docker images on CircleCI. They are pushed to terrorjack/asterius , the tags are git revisions. terrorjack/asterius:latest correspond to latest revision on master . Put input program in a directory (e.g. ~/mirror ), then map the directory to a Docker volume: terrorjack@ubuntu:~$ docker run -it -v ~/mirror:/mirror terrorjack/asterius root@76bcb511663d:~# cd /mirror root@76bcb511663d:/mirror# ahc-link --help ...","title":"Using a pre-built Docker image"},{"location":"building/#building-custom-ghc","text":"asterius requires a forked ghc which can be found here . We are looking forward to building asterius with vanilla ghc-head in the long run, but at the moment, we use our own ghc fork so it's easy to test radical changes on ghc itself. The building guide of ghc can be found here . On Linux/macOS, a prebuilt ghc tarball is provided. It's already included in stack.yaml . Note that the Windows bindist does not provide prof libs/haddock (due to AppVeyor build time restriction).","title":"Building custom ghc"},{"location":"building/#extra-dependencies","text":"Besides the custom ghc , these dependencies are also required: cmake / make / g++ : For building in-tree binaryen autoconf : For booting ghc-prim / base nodejs : For running tests. Ensure the latest version is used, since we rely on some recent V8 experimental features (e.g. BigInt support) stack : Someday cabal may also work, no specific obstacles anyway.","title":"Extra dependencies"},{"location":"building/#building-asterius","text":"stack build asterius . That's it. Set MAKEFLAGS=-j8 to pass flags to make for parallel building of binaryen . After the dust settles, run stack exec ahc-boot to perform booting. Set the ASTERIUS_DEBUG environment variable to make ahc-boot print IRs to text files which are useful when debugging compiled code of standard libraries. Be aware that this flag slows down the booting process significantly!","title":"Building asterius"},{"location":"cabal/","text":"Cabal support Asterius now has preliminary Cabal support. By substituting toolchain executables like ghc / ghc-pkg and supplying some other configure options, Cabal can build static libraries and \"executables\" using asterius. The \"executables\" can be quickly converted to node/web artifacts using ahc-dist . We also provide ahc-cabal which is a wrapper for cabal . ahc-cabal works with typical nix-style commands like new-update / new-build , etc. The legacy commands with v1 prefix may also work.","title":"Cabal support"},{"location":"cabal/#cabal-support","text":"Asterius now has preliminary Cabal support. By substituting toolchain executables like ghc / ghc-pkg and supplying some other configure options, Cabal can build static libraries and \"executables\" using asterius. The \"executables\" can be quickly converted to node/web artifacts using ahc-dist . We also provide ahc-cabal which is a wrapper for cabal . ahc-cabal works with typical nix-style commands like new-update / new-build , etc. The legacy commands with v1 prefix may also work.","title":"Cabal support"},{"location":"custom-ghc/","text":"About the custom GHC fork Asterius currently is based on a custom GHC fork maintained here . We regularly merge master commits back, build new bindists and use them on CI, to ensure our fork doesn't get bit-rotten and become painful to upstream back. Here is a complete list of differences we've made in the fork (surprisingly few at the moment): Enable D5079 and D5082 , which are kindly offered by Joachim Breitner but not all landed in master yet. Implement additional Hooks : tcRnModuleHook , stgCmmHook , cmmToRawCmmHook . Link ghc-pkg / hsc2hs with -threaded . See the circleci-ghc-bindist / appveyor-ghc-bindist branches of asterius repo for CI scripts to build bindists for the fork. The AppVeyor script is broken for now.","title":"About the custom GHC fork"},{"location":"custom-ghc/#about-the-custom-ghc-fork","text":"Asterius currently is based on a custom GHC fork maintained here . We regularly merge master commits back, build new bindists and use them on CI, to ensure our fork doesn't get bit-rotten and become painful to upstream back. Here is a complete list of differences we've made in the fork (surprisingly few at the moment): Enable D5079 and D5082 , which are kindly offered by Joachim Breitner but not all landed in master yet. Implement additional Hooks : tcRnModuleHook , stgCmmHook , cmmToRawCmmHook . Link ghc-pkg / hsc2hs with -threaded . See the circleci-ghc-bindist / appveyor-ghc-bindist branches of asterius repo for CI scripts to build bindists for the fork. The AppVeyor script is broken for now.","title":"About the custom GHC fork"},{"location":"debugging/","text":"The runtime debugging feature There is a runtime debugging mode which can be enabled by the --debug flag for ahc-link . When enabled, the compiler inserts \"tracing\" instructions in the following places: The start of a function/basic block SetLocal when the local type is I64 Memory load/stores, when the value type is I64 The tracing messages are quite helpful in observing control flow transfers and memory operations. Remember to also use the --output-link-report flag to dump the linking report, which contains mapping from data/function symbols to addresses. The runtime debugging mode also enables a \"memory trap\" which intercepts every memory load/store instruction and checks if the address is null pointer or other uninitialized regions of the linear memory. The program immediately aborts if an invalid address is encountered. (When debugging mode is switched off, program continues execution and the rest of control flow is all undefined behavior!) Virtual address spaces Remember that we're compiling to wasm32 which has a 32-bit address space, but the host GHC is actually 64-bits, so all pointers in asterius are 64-bits, and upon load / store / call_indirect , we truncate the 64-bit pointer, using only the lower 32-bits for indexing. The higher 32-bits of pointers are idle tag bits at our disposal, so, we implemented simple virtual address spaces. The linker/runtime is aware of the distinction between: The physical address, which is either an i32 index of the linear memory for data, or an i32 index of the table for functions. The logical address, which is the i64 pointer value we're passing around. All access to the memory/table is achieved by using the logical address. The access operations are accompanied by a mapping operation which translates a logical address to a physical one. Currently it's just a truncate, but in the future we may get a more feature-complete mmap / munmap implementation, and some additional computation may occur when address translation is done. We chose two magic numbers (in Asterius.Internals.MagicNumber ) as the tag bits for data/function pointers. The numbers are chosen so that when applied, the logical address does not exceed JavaScript's safe integer limit. When we emit debug log entries, we may encounter various i64 values. We examine the higher 32-bits, and if it matches the pointer tag bits, we do a lookup in the data/function symbol table, and if there's a hit, we output the symbol along the value. This spares us the pain to keep a lot of symbol/address mappings in our working memory when examining the debug logs. Some false positives (e.g. some random intermediate i64 value in a Haskell computation accidently collides with a logical address) may exist in theory, but the probability should be very low. Note that for consistency between vanilla/debug mode, the virtual address spaces are in effect even in vanilla mode. This won't add extra overhead, since the truncate instruction for 64-bit addresses has been present since the beginning. Complete list of emitted debugging log entries Assertions: some hand-written WebAssembly functions in Asterius.Builtins contain assertions which are only active in debugging mode. Failure of an assertion causes a string error message to be printed, and the whole execution flow aborted. Memory traps: In Asterius.MemoryTrap , we implement a rewriting pass which rewrites all load/store instructions into invocations of load/store wrapper functions. The wrapper functions are defined in Asterius.Builtins , which checks the address and traps if it's an invalid one (null pointer, uninitialized region, etc). Control-flow: In Asterius.Tracing , we implement a rewriting pass on functions (which are later invoked at link-time in Asterius.Resolve ), which emits messages when: Entering a Cmm function. Entering a basic block. To make sense of block ids, you need to dump pre-linking IRs (which isn't processed by the relooper yet, and preserves the control-flow graph structure) Assigning a value to an i64 local. To make sense of local ids, dump IRs. Also note that the local ids here doesn't match the actual local ids in wasm binary code (there is a re-mapping upon serialization), but it shouldn't be a problem since we are debugging the higher level IR here. Dumping IRs There are multiple ways to dump IRs: Via GHC flags: GHC flags like -ddump-to-file -ddump-cmm-raw dump pretty-printed GHC IRs to files. Via environment variable: Set the ASTERIUS_DEBUG environment variable, then during booting, a number of IRs (mainly raw Cmm in its AST form, instead of pretty-printed form) will be dumped. Via ahc-link flag: Use ahc-link --output-ir to dump IRs when compiling user code.","title":"The runtime debugging feature"},{"location":"debugging/#the-runtime-debugging-feature","text":"There is a runtime debugging mode which can be enabled by the --debug flag for ahc-link . When enabled, the compiler inserts \"tracing\" instructions in the following places: The start of a function/basic block SetLocal when the local type is I64 Memory load/stores, when the value type is I64 The tracing messages are quite helpful in observing control flow transfers and memory operations. Remember to also use the --output-link-report flag to dump the linking report, which contains mapping from data/function symbols to addresses. The runtime debugging mode also enables a \"memory trap\" which intercepts every memory load/store instruction and checks if the address is null pointer or other uninitialized regions of the linear memory. The program immediately aborts if an invalid address is encountered. (When debugging mode is switched off, program continues execution and the rest of control flow is all undefined behavior!)","title":"The runtime debugging feature"},{"location":"debugging/#virtual-address-spaces","text":"Remember that we're compiling to wasm32 which has a 32-bit address space, but the host GHC is actually 64-bits, so all pointers in asterius are 64-bits, and upon load / store / call_indirect , we truncate the 64-bit pointer, using only the lower 32-bits for indexing. The higher 32-bits of pointers are idle tag bits at our disposal, so, we implemented simple virtual address spaces. The linker/runtime is aware of the distinction between: The physical address, which is either an i32 index of the linear memory for data, or an i32 index of the table for functions. The logical address, which is the i64 pointer value we're passing around. All access to the memory/table is achieved by using the logical address. The access operations are accompanied by a mapping operation which translates a logical address to a physical one. Currently it's just a truncate, but in the future we may get a more feature-complete mmap / munmap implementation, and some additional computation may occur when address translation is done. We chose two magic numbers (in Asterius.Internals.MagicNumber ) as the tag bits for data/function pointers. The numbers are chosen so that when applied, the logical address does not exceed JavaScript's safe integer limit. When we emit debug log entries, we may encounter various i64 values. We examine the higher 32-bits, and if it matches the pointer tag bits, we do a lookup in the data/function symbol table, and if there's a hit, we output the symbol along the value. This spares us the pain to keep a lot of symbol/address mappings in our working memory when examining the debug logs. Some false positives (e.g. some random intermediate i64 value in a Haskell computation accidently collides with a logical address) may exist in theory, but the probability should be very low. Note that for consistency between vanilla/debug mode, the virtual address spaces are in effect even in vanilla mode. This won't add extra overhead, since the truncate instruction for 64-bit addresses has been present since the beginning.","title":"Virtual address spaces"},{"location":"debugging/#complete-list-of-emitted-debugging-log-entries","text":"Assertions: some hand-written WebAssembly functions in Asterius.Builtins contain assertions which are only active in debugging mode. Failure of an assertion causes a string error message to be printed, and the whole execution flow aborted. Memory traps: In Asterius.MemoryTrap , we implement a rewriting pass which rewrites all load/store instructions into invocations of load/store wrapper functions. The wrapper functions are defined in Asterius.Builtins , which checks the address and traps if it's an invalid one (null pointer, uninitialized region, etc). Control-flow: In Asterius.Tracing , we implement a rewriting pass on functions (which are later invoked at link-time in Asterius.Resolve ), which emits messages when: Entering a Cmm function. Entering a basic block. To make sense of block ids, you need to dump pre-linking IRs (which isn't processed by the relooper yet, and preserves the control-flow graph structure) Assigning a value to an i64 local. To make sense of local ids, dump IRs. Also note that the local ids here doesn't match the actual local ids in wasm binary code (there is a re-mapping upon serialization), but it shouldn't be a problem since we are debugging the higher level IR here.","title":"Complete list of emitted debugging log entries"},{"location":"debugging/#dumping-irs","text":"There are multiple ways to dump IRs: Via GHC flags: GHC flags like -ddump-to-file -ddump-cmm-raw dump pretty-printed GHC IRs to files. Via environment variable: Set the ASTERIUS_DEBUG environment variable, then during booting, a number of IRs (mainly raw Cmm in its AST form, instead of pretty-printed form) will be dumped. Via ahc-link flag: Use ahc-link --output-ir to dump IRs when compiling user code.","title":"Dumping IRs"},{"location":"ghc-testsuite-categorization/","text":"Unreachable at base_GHCziFloat_.Lc3eRO Unreachable at stg_raisezh typecheck test cases: Unreachable at base_GHCziFingerprint_.Lcb0BY numeric, perf, array: Cannot read property 'toString' of undefined | IntegerManager.integerLogBase (file:///tmp/asterius/asterius/test/ghc-testsuite/perf/rts.integer.mjs:73:33 rts, codegen: unreachable at: base_SystemziEnvironment_.LcbJdt integerconversions.hs : float unrepresentable in integer range deriving tests: unreachable base_TextziReadziLex_.Lc3IkO perf/T3245.hs : unreachable at base_SystemziCPUTimeziPosixziClockGetTime_ array/arr012 : unreachable at base_GHCziUnicode_.Lc2dkv applicative do: Unreachable at: prettyzm1zi1zi3zi6zm5t2Wzzuijam22NUf3MpOoWu_TextziPrettyPrintziAnnotatedziHughesPJ_ Some numeric test cases have wrong results: expected (...) but got (...) deriving, codegen: Unreachable base_GHCziUnicode_zdwgeneralCategory_entry probably due to use of read codegen: invalid index into function table codegen: unreachable at scheduleWaitThread codegen: memory access out of bounds at stg_noDuplicatezh codegen: unreachable base_GHCziFloat_zdwzdsformatRealFloatAlt1_entry codegen: Offset is outside the bounds of the DataView at DataView.getUint32 at Memory.i32Load at ... at GC.gcRootTSO","title":"Ghc testsuite categorization"},{"location":"hacking/","text":"Hacking guide Hacking with ghcid A known-to-work workflow of hacking asterius is using ghcid . We also include an example .ghcid file, so running ghcid at the project root directory shall work out of the box. Some notes regarding the usage of ghcid : Multiple lib targets can be loaded at once, but only one main target (exe/test) can be loaded. When hacking a specific exe/test, modify the local .ghcid file first, and don't commit the change. And before commiting, it would be nice to run stack build --test --no-run-tests to make sure all executables are up-to-date and not broken by lib changes. If some weird linker-related error related to ghc-toolkit or binaryen pops up when loading ghcid , try adding ghc-toolkit:lib or binaryen:lib to one of the ghcid targets in .ghcid . Boot cache maintainence As described in the building guide, stack build only builds the asterius compiler itself; additionally we need to run stack exec ahc-boot to run the compiler on the boot libs. This process is typically only needed once, but there are cases when it needs to be re-run: The boot libs in ghc-toolkit/boot-libs are modified. The Asterius.Types module is modified, so the IR types have changed. The Asterius.CodeGen module is modified and you're sure different code will be generated when compiling the same Haskell/Cmm files. Most other modifications in the asterius lib/exes won't need a reboot. Specifically: Asterius.Builtins modifications don't impact the boot cache. The builtin module is generated on the fly with every linker invocation. When rebooting, run utils/clean.sh in the project root directory to purge the cache, then rerun stack build and stack exec ahc-boot . The ahc-boot process is configurable via these environment variables: ASTERIUS_CONFIGURE_OPTIONS ASTERIUS_BUILD_OPTIONS ASTERIUS_INSTALL_OPTIONS A common usage is setting ASTERIUS_BUILD_OPTIONS=-j8 to enable parallelism in booting, reducing your coffee break time. Adding a test case To add a test case, it is best to replicate what has been done for an existing testcase. For example, git grep bytearraymini should show all the places where the test case bytearraymini has been used. Replicating the same files for a new test case should \"just work\". Using wabt We also include wabt in the source tree and pack it as a Cabal package. So stack build wabt will build the wabt binaries. To install the binaries to a specific location (e.g. ~/.local/bin ), set the WABT_BINDIR environment variables before building; stack install doesn't properly copy the binaries yet. The wabt setup script uses make , so it's possible to use MAKEFLAGS environment variable to pass additional arguments to make , e.g. setting MAKEFLAGS=-j8 to speed it up. The wabt package exposes Paths_wabt , so by using Paths_wabt.getBinDir you can access the wabt binary location in Haskell. This can be useful when implementing Haskell wrappers. Debugging circleCI All instructions documented here depend on having the circleci command line tool installed. Validating config To validate the circleCI config, use: circleci config validate Run CircleCI job locally To run a job with circleCI locally for debugging: Install docker Get the docker daemon running. Run: $ circleci local execute --job <job-name> For example: $ circleci local execute --job asterius-test","title":"Hacking guide"},{"location":"hacking/#hacking-guide","text":"","title":"Hacking guide"},{"location":"hacking/#hacking-with-ghcid","text":"A known-to-work workflow of hacking asterius is using ghcid . We also include an example .ghcid file, so running ghcid at the project root directory shall work out of the box. Some notes regarding the usage of ghcid : Multiple lib targets can be loaded at once, but only one main target (exe/test) can be loaded. When hacking a specific exe/test, modify the local .ghcid file first, and don't commit the change. And before commiting, it would be nice to run stack build --test --no-run-tests to make sure all executables are up-to-date and not broken by lib changes. If some weird linker-related error related to ghc-toolkit or binaryen pops up when loading ghcid , try adding ghc-toolkit:lib or binaryen:lib to one of the ghcid targets in .ghcid .","title":"Hacking with ghcid"},{"location":"hacking/#boot-cache-maintainence","text":"As described in the building guide, stack build only builds the asterius compiler itself; additionally we need to run stack exec ahc-boot to run the compiler on the boot libs. This process is typically only needed once, but there are cases when it needs to be re-run: The boot libs in ghc-toolkit/boot-libs are modified. The Asterius.Types module is modified, so the IR types have changed. The Asterius.CodeGen module is modified and you're sure different code will be generated when compiling the same Haskell/Cmm files. Most other modifications in the asterius lib/exes won't need a reboot. Specifically: Asterius.Builtins modifications don't impact the boot cache. The builtin module is generated on the fly with every linker invocation. When rebooting, run utils/clean.sh in the project root directory to purge the cache, then rerun stack build and stack exec ahc-boot . The ahc-boot process is configurable via these environment variables: ASTERIUS_CONFIGURE_OPTIONS ASTERIUS_BUILD_OPTIONS ASTERIUS_INSTALL_OPTIONS A common usage is setting ASTERIUS_BUILD_OPTIONS=-j8 to enable parallelism in booting, reducing your coffee break time.","title":"Boot cache maintainence"},{"location":"hacking/#adding-a-test-case","text":"To add a test case, it is best to replicate what has been done for an existing testcase. For example, git grep bytearraymini should show all the places where the test case bytearraymini has been used. Replicating the same files for a new test case should \"just work\".","title":"Adding a test case"},{"location":"hacking/#using-wabt","text":"We also include wabt in the source tree and pack it as a Cabal package. So stack build wabt will build the wabt binaries. To install the binaries to a specific location (e.g. ~/.local/bin ), set the WABT_BINDIR environment variables before building; stack install doesn't properly copy the binaries yet. The wabt setup script uses make , so it's possible to use MAKEFLAGS environment variable to pass additional arguments to make , e.g. setting MAKEFLAGS=-j8 to speed it up. The wabt package exposes Paths_wabt , so by using Paths_wabt.getBinDir you can access the wabt binary location in Haskell. This can be useful when implementing Haskell wrappers.","title":"Using wabt"},{"location":"hacking/#debugging-circleci","text":"All instructions documented here depend on having the circleci command line tool installed.","title":"Debugging circleCI"},{"location":"hacking/#validating-config","text":"To validate the circleCI config, use: circleci config validate","title":"Validating config"},{"location":"hacking/#run-circleci-job-locally","text":"To run a job with circleCI locally for debugging: Install docker Get the docker daemon running. Run: $ circleci local execute --job <job-name> For example: $ circleci local execute --job asterius-test","title":"Run CircleCI job locally"},{"location":"ir/","text":"IR types and transformation passes This section explains various IR types in asterius, and hopefully presents a clear picture of how information flows from Haskell to WebAssembly. (There's a similar section in jsffi.md which explains implementation details of JSFFI) Cmm IR Everything starts from Cmm, or more specifically, \"raw\" Cmm which satisfies: All calls are tail calls, parameters are passed by global registers like R1 or on the stack. All info tables are converted to binary data segments. Check Cmm module in ghc package to get started on Cmm. Asterius obtains in-memory raw Cmm via: cmmToRawCmmHook in our custom GHC fork. This allow us to lay our fingers on Cmm generated by either compiling Haskell modules, or .cmm files (which are in rts ) There is some abstraction in ghc-toolkit , the compiler logic is actually in the Compiler datatype as some callbacks, and ghc-toolkit converts them to hooks, frontend plugins and ghc executable wrappers. There is one minor annoyance with the Cmm types in GHC (or any other GHC IR type): it's very hard to serialize/deserialize them without setting up complicated contexts related to package databases, etc. To experiment with new backends, it's reasonable to marshal to a custom serializable IR first. Pre-linking expression IR We then marshal raw Cmm to an expression IR defined in Asterius.Types . Each compilation unit (Haskell module or .cmm file) maps to one AsteriusModule , and each AsteriusModule is serialized to a .asterius_o object file which will be deserialized at link time. Since we serialize/deserialize a structured expression IR faithfully, it's possible to perform aggressive LTO by traversing/rewriting IR at link time, and that's what we're doing right now. The expression IR is mostly a Haskell modeling of a subset of binaryen 's expression IR, with some additions: Unresolved related variants, which allow us to use a symbol as an expression. At link time, the symbols are re-written to absolute addresses. Unresolved locals/globals. At link time, unresolved locals are laid out to wasm locals, and unresolved globals (which are really just Cmm global regs) become fields in the global Capability's StgRegTable . EmitErrorMessage , as a placeholder of emitting a string error message then trapping. At link time, such error messages are collected into an \"error message pool\", and the wasm code is just \"calling some error message reporting function with an array index\". Null . We're civilized, educated functional programmers and should really be using Maybe Expression in some fields instead of adding a Null constructor, but this is just handy. Blame me. It's possible to encounter things we can't handle in Cmm (unsupported primops, etc). So AsteriusModule also contains compile-time error messages when something isn't supported, but the errors are not reported, instead they are deferred to runtime error messages. (Ideally link-time, but it turns out to be hard) The symbols are simply converted to Z-encoded strings that also contain module prefixes, and they are assumed to be unique across different compilation units. The store There's an AsteriusStore type in Asterius.Types . It's an immutable data structure that maps symbols to underlying entities in the expression IR for every single module, and is a critical component of the linker. Modeling the store as a self-contained data structure makes it pleasant to write linker logic, at the cost of exploding RAM usage. So we implemented a poor man's KV store in Asterius.Store which performs lazy-loading of modules: when initializing the store, we only load the symbols, but not the actual modules; only when a module is \"requested\" for the first time, we perform deserialization for that module. AsteriusStore supports merging. It's a handy operation, since we can first initialize a \"global\" store that represents the standard libraries, then make another store based on compiling user input, simply merge the two and we can start linking from the output store. Post-linking expression IR At link time, we take AsteriusStore which contains everything (standard libraries and user input code), then performs live-code discovery: starting from a \"root symbol set\" (something like Main_main_closure ), iteratively fetch the entity from the store, traverse the AST and collect new symbols. When we reach a fixpoint, that fixpoint is the outcome of dependency analysis, representing a self-contained wasm module. We then do some rewriting work on the self contained module: making symbol tables, rewriting symbols to absolute addresses, using our own relooper to convert from control-flow graphs to structured control flow, etc. Most of the logic is in Asterius.Resolve . The output of linker is Module . It differs from AsteriusModule , and although it shares quite some datatypes with AsteriusModule (for example, Expression ), it guarantees that some variants will not appear (for example, Unresolved* ). A Module is ready to be fed to a backend which emits real wasm binary code. There are some useful linker byproducts. For example, there's LinkReport which contains mappings from symbols to addresses which will be lost in wasm binary code, but is still useful for debugging. Generating binary code via binaryen Once we have a Module (which is essentially just Haskell modeling of binaryen C API), we can invoke binaryen to validate it and generate wasm binary code. The low-level bindings are maintained in the binaryen package, and Asterius.Marshal contains the logic to call the imported functions to do actual work. Generating binary code via wasm-toolkit We can also convert Module to IR types of wasm-toolkit , which is our native Haskell wasm engine. It's now the default backend of ahc-link , but the binaryen backend can still be chosen by ahc-link --binaryen . Generating JavaScript stub script To make it actually run in Node.js/Chrome, we need two pieces of JavaScript code: Common runtime which can be reused across different asterius compiled modules. It's in asterius/rts/rts.js . Stub code which contains specific information like error messages, etc. The linker generates stub script along with wasm binary code, and concats the runtime and the stub script to a self-contained JavaScript file which can be run or embedded. It's possible to specify JavaScript \"target\" to either Node.js or Chrome via ahc-link flags.","title":"IR types and transformation passes"},{"location":"ir/#ir-types-and-transformation-passes","text":"This section explains various IR types in asterius, and hopefully presents a clear picture of how information flows from Haskell to WebAssembly. (There's a similar section in jsffi.md which explains implementation details of JSFFI)","title":"IR types and transformation passes"},{"location":"ir/#cmm-ir","text":"Everything starts from Cmm, or more specifically, \"raw\" Cmm which satisfies: All calls are tail calls, parameters are passed by global registers like R1 or on the stack. All info tables are converted to binary data segments. Check Cmm module in ghc package to get started on Cmm. Asterius obtains in-memory raw Cmm via: cmmToRawCmmHook in our custom GHC fork. This allow us to lay our fingers on Cmm generated by either compiling Haskell modules, or .cmm files (which are in rts ) There is some abstraction in ghc-toolkit , the compiler logic is actually in the Compiler datatype as some callbacks, and ghc-toolkit converts them to hooks, frontend plugins and ghc executable wrappers. There is one minor annoyance with the Cmm types in GHC (or any other GHC IR type): it's very hard to serialize/deserialize them without setting up complicated contexts related to package databases, etc. To experiment with new backends, it's reasonable to marshal to a custom serializable IR first.","title":"Cmm IR"},{"location":"ir/#pre-linking-expression-ir","text":"We then marshal raw Cmm to an expression IR defined in Asterius.Types . Each compilation unit (Haskell module or .cmm file) maps to one AsteriusModule , and each AsteriusModule is serialized to a .asterius_o object file which will be deserialized at link time. Since we serialize/deserialize a structured expression IR faithfully, it's possible to perform aggressive LTO by traversing/rewriting IR at link time, and that's what we're doing right now. The expression IR is mostly a Haskell modeling of a subset of binaryen 's expression IR, with some additions: Unresolved related variants, which allow us to use a symbol as an expression. At link time, the symbols are re-written to absolute addresses. Unresolved locals/globals. At link time, unresolved locals are laid out to wasm locals, and unresolved globals (which are really just Cmm global regs) become fields in the global Capability's StgRegTable . EmitErrorMessage , as a placeholder of emitting a string error message then trapping. At link time, such error messages are collected into an \"error message pool\", and the wasm code is just \"calling some error message reporting function with an array index\". Null . We're civilized, educated functional programmers and should really be using Maybe Expression in some fields instead of adding a Null constructor, but this is just handy. Blame me. It's possible to encounter things we can't handle in Cmm (unsupported primops, etc). So AsteriusModule also contains compile-time error messages when something isn't supported, but the errors are not reported, instead they are deferred to runtime error messages. (Ideally link-time, but it turns out to be hard) The symbols are simply converted to Z-encoded strings that also contain module prefixes, and they are assumed to be unique across different compilation units.","title":"Pre-linking expression IR"},{"location":"ir/#the-store","text":"There's an AsteriusStore type in Asterius.Types . It's an immutable data structure that maps symbols to underlying entities in the expression IR for every single module, and is a critical component of the linker. Modeling the store as a self-contained data structure makes it pleasant to write linker logic, at the cost of exploding RAM usage. So we implemented a poor man's KV store in Asterius.Store which performs lazy-loading of modules: when initializing the store, we only load the symbols, but not the actual modules; only when a module is \"requested\" for the first time, we perform deserialization for that module. AsteriusStore supports merging. It's a handy operation, since we can first initialize a \"global\" store that represents the standard libraries, then make another store based on compiling user input, simply merge the two and we can start linking from the output store.","title":"The store"},{"location":"ir/#post-linking-expression-ir","text":"At link time, we take AsteriusStore which contains everything (standard libraries and user input code), then performs live-code discovery: starting from a \"root symbol set\" (something like Main_main_closure ), iteratively fetch the entity from the store, traverse the AST and collect new symbols. When we reach a fixpoint, that fixpoint is the outcome of dependency analysis, representing a self-contained wasm module. We then do some rewriting work on the self contained module: making symbol tables, rewriting symbols to absolute addresses, using our own relooper to convert from control-flow graphs to structured control flow, etc. Most of the logic is in Asterius.Resolve . The output of linker is Module . It differs from AsteriusModule , and although it shares quite some datatypes with AsteriusModule (for example, Expression ), it guarantees that some variants will not appear (for example, Unresolved* ). A Module is ready to be fed to a backend which emits real wasm binary code. There are some useful linker byproducts. For example, there's LinkReport which contains mappings from symbols to addresses which will be lost in wasm binary code, but is still useful for debugging.","title":"Post-linking expression IR"},{"location":"ir/#generating-binary-code-via-binaryen","text":"Once we have a Module (which is essentially just Haskell modeling of binaryen C API), we can invoke binaryen to validate it and generate wasm binary code. The low-level bindings are maintained in the binaryen package, and Asterius.Marshal contains the logic to call the imported functions to do actual work.","title":"Generating binary code via binaryen"},{"location":"ir/#generating-binary-code-via-wasm-toolkit","text":"We can also convert Module to IR types of wasm-toolkit , which is our native Haskell wasm engine. It's now the default backend of ahc-link , but the binaryen backend can still be chosen by ahc-link --binaryen .","title":"Generating binary code via wasm-toolkit"},{"location":"ir/#generating-javascript-stub-script","text":"To make it actually run in Node.js/Chrome, we need two pieces of JavaScript code: Common runtime which can be reused across different asterius compiled modules. It's in asterius/rts/rts.js . Stub code which contains specific information like error messages, etc. The linker generates stub script along with wasm binary code, and concats the runtime and the stub script to a self-contained JavaScript file which can be run or embedded. It's possible to specify JavaScript \"target\" to either Node.js or Chrome via ahc-link flags.","title":"Generating JavaScript stub script"},{"location":"jsffi/","text":"JavaScript FFI There is a prototype implementation of foreign import javascript right now, check the jsffi / teletype unit tests for details. The syntax is like: import Asterius.Types foreign import javascript \"new Date()\" current_time :: IO JSVal foreign import javascript \"console.log(${1})\" js_print :: JSVal -> IO () The source text of foreign import javascript should be a valid JavaScript expression. You can use ${n} to refer to the nth function parameter starting from 1. By using the IIFE(Immediately Invoked Function Expression) design pattern, it's even possible to define local variables and write for loops. Supported basic types are: Ptr FunPtr StablePtr Bool Int Word Char Float Double JSVal / JSArrayBuffer / JSString / JSArray For the lifted basic types, the result can be wrapped in IO (or not). There's also limited support for unlifted FFI types: StablePtr# a Addr# ByteArray# MutableByteArray# s Char# Int# Word# Float# Double# These unlifted FFI types can be used in a foreign import javascript clause (but not export .) The results can't be wrapped in IO . JSVal is defined in Asterius.Types in the patched ghc-prim package. In the Haskell land, JSVal is first-class and opaque: you can pass it around, put it in a data structure, etc, but under the hood it's just a handle. The runtime maintains mappings from handles to real JavaScript objects. Normally, the Haskell FFI mechanism permits defining newtype s to the marshallable basic types, and the wrapping/unwrapping is done automatically. However, this doesn't work yet due to the way we implement JSFFI right now. You can define a newtype to JSVal / JSWhatever , but in a foreign import javascript / foreign export javascript declaration, you still must use one of the builtin JS* types, and when using imported functions, you need to manually coerce them ( coerce works when Asterius.Types is imported). Also, a prototype of foreign export javascript is implemented, check jsffi for details. The syntax is roughly: foreign export javascript \"mult_hs\" (*) :: Int -> Int -> Int In a Haskell module, one can specify the exported function name (must be globally unique), along with its Haskell identifier and type. One can specify ahc-link --export-function=mult_hs to make the linker include the relevant bits in final WebAssembly binary, and export mult_hs as a regular WebAssembly export function. After calling hs_init to initialize the runtime, one can call mult_hs just like a regular JavaScript function. Converting between Haskell and JavaScript types The Asterius.Types / Asterius.ByteString modules provide some high-level functions for converting between Haskell and JavaScript types: fromJSString :: JSString -> [Char] toJSString :: [Char] -> JSString fromJSArray :: JSArray -> [JSVal] toJSArray :: [JSVal] -> JSArray byteStringFromJSArrayBuffer :: JSArrayBuffer -> ByteString byteStringToJSArrayBuffer :: ByteString -> JSArrayBuffer It's possible to define them just by using the basic JSFFI mechanism, but those functions are backed by special runtime interfaces which makes them a lot faster. Most notably, the fromJS* functions directly traverse the JavaScript value and build a fully-evaluated Haskell data structure on the heap in one pass. What's permitted in foreign import javascript In a foreign import javascript declaration, you can access all properties of the global object ( window in browsers, global in node.js), so all functionalities of standard JavaScript is permitted. Additionally, the __asterius_jsffi object is in scope; it is initialized before instantiating the WebAssembly instance, and contains the runtime interfaces used to support the JSFFI features (e.g. manipulation of JSVal s). You may check rts/rts.js to see what __asterius_jsffi contains, but we don't recommend using it in your code since it's intended to be an implementation detail; shall you feel the need to access it, please file an issue instead and we'll add your missing functionality as proper Haskell/JavaScript interfaces instead. Implementation This subsection presents a high-level overview on the implementation of JSFFI, based on the information flow from syntactic sugar to generated WebAssembly/JavaScript code. It's not a required reading for users of the JSFFI feature. Syntactic sugar As documented in previous sections, one can write foreign import javascript or foreign export javascript clauses in a .hs module. How are they processed? The logic resides in Asterius.JSFFI . First, there is addFFIProcessor , which given a Compiler (defined in ghc-toolkit ), returns a new Compiler and a callback to fetch a stub module. The details of Compiler 's implementation are not relevant here, just think of it as an abstraction layer to fetch/modify GHC IRs without dealing with all the details of GHC API. addFFIProcessor adds one functionality to the input Compiler : rewrite parsed Haskell AST and handle the foreign import javascript / foreign export javascript syntactic sugar. After rewriting, JavaScript FFI is really turned into C FFI, so type-checking/code generation proceeds as normal. After the parsed AST is processed, a \"stub module\" of type AsteriusModule is generated and can be later fetched given an AsteriusModuleSymbol . It contains JSFFI related information of type FFIMarshalState . Both AsteriusModule and FFIMarshalState types has Semigroup instance so they can be combined later at link-time. TODO Adding a JSFFI basic type Look at the following places: Asterius.JSFFI module. All JavaScript reference types are uniformly handled as FFI_JSVAL , while value types are treated as FFI_VAL . Assuming we are adding a value type. Add logic to: marshalToFFIValueType : Recognize the value type in parsed AST, and translate to FFI_VAL Asterius.Builtins module. Add the corresponding rts_mkXX / rts_getXX builtin functions. They are required for stub functions of foreign export javascript .","title":"JavaScript FFI"},{"location":"jsffi/#javascript-ffi","text":"There is a prototype implementation of foreign import javascript right now, check the jsffi / teletype unit tests for details. The syntax is like: import Asterius.Types foreign import javascript \"new Date()\" current_time :: IO JSVal foreign import javascript \"console.log(${1})\" js_print :: JSVal -> IO () The source text of foreign import javascript should be a valid JavaScript expression. You can use ${n} to refer to the nth function parameter starting from 1. By using the IIFE(Immediately Invoked Function Expression) design pattern, it's even possible to define local variables and write for loops. Supported basic types are: Ptr FunPtr StablePtr Bool Int Word Char Float Double JSVal / JSArrayBuffer / JSString / JSArray For the lifted basic types, the result can be wrapped in IO (or not). There's also limited support for unlifted FFI types: StablePtr# a Addr# ByteArray# MutableByteArray# s Char# Int# Word# Float# Double# These unlifted FFI types can be used in a foreign import javascript clause (but not export .) The results can't be wrapped in IO . JSVal is defined in Asterius.Types in the patched ghc-prim package. In the Haskell land, JSVal is first-class and opaque: you can pass it around, put it in a data structure, etc, but under the hood it's just a handle. The runtime maintains mappings from handles to real JavaScript objects. Normally, the Haskell FFI mechanism permits defining newtype s to the marshallable basic types, and the wrapping/unwrapping is done automatically. However, this doesn't work yet due to the way we implement JSFFI right now. You can define a newtype to JSVal / JSWhatever , but in a foreign import javascript / foreign export javascript declaration, you still must use one of the builtin JS* types, and when using imported functions, you need to manually coerce them ( coerce works when Asterius.Types is imported). Also, a prototype of foreign export javascript is implemented, check jsffi for details. The syntax is roughly: foreign export javascript \"mult_hs\" (*) :: Int -> Int -> Int In a Haskell module, one can specify the exported function name (must be globally unique), along with its Haskell identifier and type. One can specify ahc-link --export-function=mult_hs to make the linker include the relevant bits in final WebAssembly binary, and export mult_hs as a regular WebAssembly export function. After calling hs_init to initialize the runtime, one can call mult_hs just like a regular JavaScript function.","title":"JavaScript FFI"},{"location":"jsffi/#converting-between-haskell-and-javascript-types","text":"The Asterius.Types / Asterius.ByteString modules provide some high-level functions for converting between Haskell and JavaScript types: fromJSString :: JSString -> [Char] toJSString :: [Char] -> JSString fromJSArray :: JSArray -> [JSVal] toJSArray :: [JSVal] -> JSArray byteStringFromJSArrayBuffer :: JSArrayBuffer -> ByteString byteStringToJSArrayBuffer :: ByteString -> JSArrayBuffer It's possible to define them just by using the basic JSFFI mechanism, but those functions are backed by special runtime interfaces which makes them a lot faster. Most notably, the fromJS* functions directly traverse the JavaScript value and build a fully-evaluated Haskell data structure on the heap in one pass.","title":"Converting between Haskell and JavaScript types"},{"location":"jsffi/#whats-permitted-in-foreign-import-javascript","text":"In a foreign import javascript declaration, you can access all properties of the global object ( window in browsers, global in node.js), so all functionalities of standard JavaScript is permitted. Additionally, the __asterius_jsffi object is in scope; it is initialized before instantiating the WebAssembly instance, and contains the runtime interfaces used to support the JSFFI features (e.g. manipulation of JSVal s). You may check rts/rts.js to see what __asterius_jsffi contains, but we don't recommend using it in your code since it's intended to be an implementation detail; shall you feel the need to access it, please file an issue instead and we'll add your missing functionality as proper Haskell/JavaScript interfaces instead.","title":"What's permitted in foreign import javascript"},{"location":"jsffi/#implementation","text":"This subsection presents a high-level overview on the implementation of JSFFI, based on the information flow from syntactic sugar to generated WebAssembly/JavaScript code. It's not a required reading for users of the JSFFI feature.","title":"Implementation"},{"location":"jsffi/#syntactic-sugar","text":"As documented in previous sections, one can write foreign import javascript or foreign export javascript clauses in a .hs module. How are they processed? The logic resides in Asterius.JSFFI . First, there is addFFIProcessor , which given a Compiler (defined in ghc-toolkit ), returns a new Compiler and a callback to fetch a stub module. The details of Compiler 's implementation are not relevant here, just think of it as an abstraction layer to fetch/modify GHC IRs without dealing with all the details of GHC API. addFFIProcessor adds one functionality to the input Compiler : rewrite parsed Haskell AST and handle the foreign import javascript / foreign export javascript syntactic sugar. After rewriting, JavaScript FFI is really turned into C FFI, so type-checking/code generation proceeds as normal. After the parsed AST is processed, a \"stub module\" of type AsteriusModule is generated and can be later fetched given an AsteriusModuleSymbol . It contains JSFFI related information of type FFIMarshalState . Both AsteriusModule and FFIMarshalState types has Semigroup instance so they can be combined later at link-time.","title":"Syntactic sugar"},{"location":"jsffi/#todo","text":"","title":"TODO"},{"location":"jsffi/#adding-a-jsffi-basic-type","text":"Look at the following places: Asterius.JSFFI module. All JavaScript reference types are uniformly handled as FFI_JSVAL , while value types are treated as FFI_VAL . Assuming we are adding a value type. Add logic to: marshalToFFIValueType : Recognize the value type in parsed AST, and translate to FFI_VAL Asterius.Builtins module. Add the corresponding rts_mkXX / rts_getXX builtin functions. They are required for stub functions of foreign export javascript .","title":"Adding a JSFFI basic type"},{"location":"readings/","text":"Reading list Here is a brief list of relevant readings about GHC internals and WebAssembly suited for newcomers. GHC documentation regarding the GHC API : a nice reading for anyone looking forward to using the GHC API. GHC commentary : a wiki containing lots of additional knowledge regarding GHC's implementation. Keep in mind some content is out-dated though. Some useful entries regarding this project: Building guide . A tl;dr for this section is our CI scripts. Overview of pipeline : we use the Hooks mechanism (specifically, runPhaseHook ) to replace the default pipeline with our own, to enable manipulation of in-memory IRs. How STG works : a nice tutorial containing several examples of compiled examples, illustrating how the generated code works under the hood. The Cmm types : it's outdated and the types don't exactly match the GHC codebase now, but the explanations still shed some light on how the current Cmm types work. The runtime system : content regarding the runtime system. Understanding the Stack : A blog post explaining how generated code works at the assembly level. Also, its sequel Understanding the RealWorld The WebAssembly spec : a useful reference regarding what's already present in WebAssembly. The binaryen C API : binaryen handles WebAssembly code generation. There are a few differences regarding binaryen AST and WebAssembly AST, the most notable ones: binaryen uses a recursive BinaryenExpression which is side-effectful. The original WebAssembly standard instead uses a stack-based model and manipulates the operand stack with instructions. binaryen contains a \"Relooper\" which can recover high-level structured control flow from a CFG. However the relooper doesn't handle jumping to unknown labels (aka computed goto), so we don't use it to handle tail calls. The following entries are papers which consume much more time to read, but still quite useful for newcomers: Making a fast curry: push/enter vs. eval/apply for higher-order languages : A thorough explanation of what is STG and how it is implemented (via two different groups of rewrite rules, also with real benchmarks) The STG runtime system (revised) : Includes some details on the runtime system and worth a read. It's a myth why it's not merged with the commentary though. Install a TeX distribution like TeX Live or use a service like Overleaf to compile the .tex file to .pdf before reading. The GHC storage manager : Similar to above. Bringing the Web up to Speed with WebAssembly : The PLDI'17 paper about WebAssembly. Contains overview of WebAssembly design rationales and rules of small-step operational semantics. Finally, the GHC codebase itself is also a must-read, but since it's huge we only need to check relevant parts when unsure about its behavior. Tips on reading GHC code: There are a lot of insightful and up-to-date comments which all begin with \"Notes on xxx\". It's a pity the notes are neither collected into the sphinx-generated documentation or into the haddock docs of GHC API. When writing build.mk for compiling GHC, add HADDOCK_DOCS = YES to ensure building haddock docs of GHC API, and EXTRA_HADDOCK_OPTS += --quickjump --hyperlinked-source to enable symbol hyperlinks in the source pages. This will save you tons of time from grep ing the ghc codebase. grep ing is still unavoidable in some cases, since there's a lot of CPP involved and they aren't well handled by haddock.","title":"Reading list"},{"location":"readings/#reading-list","text":"Here is a brief list of relevant readings about GHC internals and WebAssembly suited for newcomers. GHC documentation regarding the GHC API : a nice reading for anyone looking forward to using the GHC API. GHC commentary : a wiki containing lots of additional knowledge regarding GHC's implementation. Keep in mind some content is out-dated though. Some useful entries regarding this project: Building guide . A tl;dr for this section is our CI scripts. Overview of pipeline : we use the Hooks mechanism (specifically, runPhaseHook ) to replace the default pipeline with our own, to enable manipulation of in-memory IRs. How STG works : a nice tutorial containing several examples of compiled examples, illustrating how the generated code works under the hood. The Cmm types : it's outdated and the types don't exactly match the GHC codebase now, but the explanations still shed some light on how the current Cmm types work. The runtime system : content regarding the runtime system. Understanding the Stack : A blog post explaining how generated code works at the assembly level. Also, its sequel Understanding the RealWorld The WebAssembly spec : a useful reference regarding what's already present in WebAssembly. The binaryen C API : binaryen handles WebAssembly code generation. There are a few differences regarding binaryen AST and WebAssembly AST, the most notable ones: binaryen uses a recursive BinaryenExpression which is side-effectful. The original WebAssembly standard instead uses a stack-based model and manipulates the operand stack with instructions. binaryen contains a \"Relooper\" which can recover high-level structured control flow from a CFG. However the relooper doesn't handle jumping to unknown labels (aka computed goto), so we don't use it to handle tail calls. The following entries are papers which consume much more time to read, but still quite useful for newcomers: Making a fast curry: push/enter vs. eval/apply for higher-order languages : A thorough explanation of what is STG and how it is implemented (via two different groups of rewrite rules, also with real benchmarks) The STG runtime system (revised) : Includes some details on the runtime system and worth a read. It's a myth why it's not merged with the commentary though. Install a TeX distribution like TeX Live or use a service like Overleaf to compile the .tex file to .pdf before reading. The GHC storage manager : Similar to above. Bringing the Web up to Speed with WebAssembly : The PLDI'17 paper about WebAssembly. Contains overview of WebAssembly design rationales and rules of small-step operational semantics. Finally, the GHC codebase itself is also a must-read, but since it's huge we only need to check relevant parts when unsure about its behavior. Tips on reading GHC code: There are a lot of insightful and up-to-date comments which all begin with \"Notes on xxx\". It's a pity the notes are neither collected into the sphinx-generated documentation or into the haddock docs of GHC API. When writing build.mk for compiling GHC, add HADDOCK_DOCS = YES to ensure building haddock docs of GHC API, and EXTRA_HADDOCK_OPTS += --quickjump --hyperlinked-source to enable symbol hyperlinks in the source pages. This will save you tons of time from grep ing the ghc codebase. grep ing is still unavoidable in some cases, since there's a lot of CPP involved and they aren't well handled by haddock.","title":"Reading list"},{"location":"reports/","text":"Status reports This page maintains a list of weekly status reports for the project. 2019-05-26 Covers the past week. Completed work: Merged in the ghc-testsuite work and it now runs as a regular CircleCI job, producing a CSV report and an ASCII table listing grouped test failures. Improved the runtime error messages related to unresolved symbols. Previously, when the linker spots unresolved symbols, it still produces a self-contained wasm module, using an invalid address to replace such symbols, resulting in a cryptic unreachable error message when an execution path hits that symbol. Now, the linker dynamically injects a small data segment into the wasm module upon unresolved symbols. The data segment is a runtime error message indicating the missing symbol. At runtime, when the symbol is used, it'll now show the linker-generated error message in the stack trace. Roughly a half of broken ghc tests are due to unresolved symbols, indicating missing rts functionality. Combined with the binaryen backend's ability to emit the name section, it's now much clearer to spot when a standard library function calls some unimplemented feature. Implemented unicode primitives to make GHC.Unicode at least works for ASCII, also fixing a long-standing issue related to crashing read calls. Fixed localeEncoding in GHC.IO.Encoding.Iconv , which always return UTF-8 at the moment. Combined with the unicode primitives above, this also fixes some other base functionality, e.g. withCString , and also the non-iconv TextEncoding s. Implemented floating-point c functions to fix GHC.Float . Fixed the noDuplicate# primop, now unsafePerformIO works. Fixed getProgArgv in System.Environment . Now getProgName returns the \"program name\" generated from ahc-ld output path, and getArgs always return an empty list. This is a sensible default combination sufficient to fix some ghc tests, and we don't plan to implement a richer API to support providing argv to a compiled \"executable\" yet. Fixed foreign import ccall safe , since it's used in some places in base . Fixed the performGC -like functions in System.Mem . Fixed the threadPaused rts function, which played an essential role in creating gc safepoints. Removed support for \"sync mode\" code generation, which ensures the output entry js module performs synchronous wasm compilation/instantiation. This is hardly used and it's increasingly likely we'll need to perform async rts startup at some point. Pruned legacy rts code related to the \"vault\" feature which was a workaround back in the days when we didn't have gc. Ongoing and planned work: Fix debugBelch / errorBelch , which is used in some places in base (e.g. trace ) Implement \"top handler\" for main IO closure, which prints uncaught exception to stderr before returning. This is required by tests whose expected behavior is throwing, and we need to check their .stderr files. Fix GHC.Fingerprint , which is required by anything related to Typeable , e.g. runtime type checks. This is required by fromException to be used by the top handler. Investigate an issue in iohk's fork to add nix support: after ahc-boot finishes, ahc is failing to pick up the compiled archives. 2019-05-20 Covers the last two weeks. Note that Siddharth Bhat(@bollu) joined in as a summer intern at Tweag I/O on this project. From this week on all status report entries are our collaborative efforts. Completed work: Fixed a bug in the codegen which ignored sign extension semantics when extending 8-bits/16-bits integers, resulting in wrong results of Int8# / Int16# / Word8# / Word16# related primops. Improved the monadic EDSL interface: Removed a redundant return type annotation in runEDSL calls. Supported declaring \"static\" memory regions, they can serve as static variables (as known in C-like languages) which persist across function calls. Updated binaryen and wabt . For binaryen , we: Spotted and worked around a minor problem: by default the validate function in C API implicitly sets the feature set to \"All\", enabling all wasm experimental features and causing the DataCount section to be emitted to wasm binary, which is unsupported in some old versions of V8. Implemented color API & s-expression API in C bindings, to support dumping s-expression of wasm to file. These two changes are also proposed to upstream. Tracked down the source of an old bug related to read crashing due to missing Unicode primitives in the runtime. Improved Cmm IR dumps to ease debugging. Many source comments; improved docs, with a new \"hacking\" section describing common workflow on hacking this project. Ongoing work and planned work: Integrate a part of ghc testsuite to run with asterius, collect the results into a report. Motivation: other than missing TH support that we're still stuck with, there are still other missing or broken features that we might be unaware of. To push asterius towards production-grade quality, we need a more comprehensive test suite to help us discover such edge cases. The single-module compile_and_run tests are copied from ghc tree, and we implemented a tasty driver to run them. Reusing the original Python-based test driver takes more work and we decide it's less of a priority at the moment. Roughly ~800 tests are included, and about 50% of them are failing at the moment. Remaining work: serve the report file as CircleCI artifact, merge back to master and start classifying the failed tests. Improve the debugging experience: Recovered the \"memory trap\" framework which we unfortunately dropped previously when attempting to get rid of link-time rewriting passes and make the linker faster. The new memory trap now relies on V8's experimental wasm BigInt integration feature, and covers all wasm read/write opcodes, even for builtin rts functions. Planned work for memory trap: we'll make the memory trap closely collaborate with the linker, block allocator and garbage collector, to achieve the following effects: There will be read-only/read-write regions, and we put immutable Cmm data in read-only regions to catch more potential data corruption. The recycled blocks will be marked inaccessible, any access to those blocks will trap. Basic exception handling is now implemented, the throw / catch functions in Control.Exception now work. We plan to implement a part of @bgamari's ghc gdb scripts for chrome devtools: inspecting closures and other rts data structures, walking the stack, etc. 2019-05-06 Covers the paralyzed few weeks since last report. To provide some context for further discussion, here is a brief summary of our attempts since we started to implement TH support, listing the approaches and encountered obstacles: Radical refactorings to make the linker faster. Linking for TH is quite unlike linking for regular Haskell modules: we need to support dynamic loading of compiled object files and libraries, along with splices, and the linking & execution requests may be interleaved. This required the linker to rapidly process the load requests and generate working wasm/js. This part of work is done and benefits regular linking as well. Implement ahc-iserv and TH message handlers. Delegating TH logic to the iserv process enables some degree of customization on how TH requests are handled, so we can implement wasm/js linking on the host platform. This part of work is done. Implement TH running logic. This means we need to be able to start a persistent runtime, occasionally send some pieces of wasm code, and run them to retrieve serialized results (and the wasm world may call back into the host world). To smoothen Haskell/node interaction, we revived the inline-js project and added loads of new functionality to it. It works well even outside the scope of asterius. TH runner is still the roadblock: Our first attempt was trying to support incrementally loading wasm objects, running wasm code, and transfer required runtime state through some global vars. This dragged us into a long debuggathon. We're currently at the second attempt: implementing an even more naive TH runner and reducing the debugging surface. Compared to a qualified TH runner which can be shipped, the naive version: Reuses the linking logic for regular Haskell modules. Always re-links upon running a splice. Always initiates a fresh TH state to run a splice. So. Another round of debugging here. Implementing TH is a large and challenging project which already consumed much more energy than once anticipated. At this point it might be nice to adjust our strategy a bit: Keep working on TH delivery, evaluate new means of debugging (e.g. reviving the previously lost debugging tracer, using V8 inspection of node, etc) to boost the process. Since it's likely not the last time we need to perform low-level debugging, the lessons we learn here should also be recorded and help later project contributors. Spare a part of time to work on other stuff, including but not limited to: Improve the currently ad hoc test suite, start integrating ghc tests. This will give us better idea on what's currently broken and what's not. Do some housekeeping on the issue tracker. There are a few issues reported long ago but remained since TH got all the attention. 2019-04-15 Covers last week. Ongoing work: Trying to use inline-js-core to run asterius compiled wasm/js. Works for: Running regular main actions and retrieving results. Calling exported rts internals to manipulate closures on the Haskell heap. Currently into a debugging rabbit hole related to getting simple expression splices to run and return serialized result: We can compile a splice of type like Q Exp , obtain the wasm closure, then use utilities from ghci to initiate a TH state and actually run it. We're hit with unreachable s at runtime; they're due to unresolved symbols substituted to an invalid address so to let linking pass, meaning there's hidden bug in the logic of either the linker itself, or how we obtain and compile the splices. Miscellaneous other improvements in inline-js . No more radical API changes are planned from now, and we have proper haddock documentation. Spread the word, give it a try in your projects too :) Estimated work for the week: Solve the runtime error related to the TH splices. 2019-04-08 Covers last week. Ongoing work: Finished all required inline-js improvements to make it feasible as an iserv component. Notable changes include: The half-baked JSON implementation is removed. All JSON-related logic is now based on aeson and the higher-level inline-js package is required. We used to only pass encoded JSON messages via the IPC interface. Now we pass binary messages, and thus we can directly allocate a node Buffer from a Haskell ByteString , and return the JSVal handle to Haskell. We implemented send/receive queues and fixed a race condition related to multiple receivers to a same Transport . We switched the Haskell/ node pipes from stdin / stdout to using file descriptors. This fixes the issue when inline-js-core executes wasm/js code produced by asterius, but due to calling console API in generated code, the pipes are corrupt and leaves the ahc-iserv process in an undefined state. We investigated the issue of supporting both static/dynamic import in the eval server's input code and did a prototype using the experimental vm.SourceTextModule interface in nodejs. Conclusion: it's not worth the trouble, and although static import s aren't supported by the eval server, the issue can be worked around without major changes in the asterius js codegen. Updated ghc and fixed #98, working around a Cabal bug (#4651) impacting our Cabal support. Third-party contributions: Thanks to Stuart Geipel(@pimlu) for discovering an issue in the garbage collector and providing a minimal repro (#97). Investigation of this issue required fixing the \"memory traps\"/\"tracing\" rewriting passes previously removed in order to speed up the linker, so is currently scheduled behind ongoing TH work. Thanks to Yuji Yamamoto(@igrep) for discovering an issue in the Cabal support (#98), and an issue in the JSFFI implementation (#102). Estimated work for the week: Just finish the iserv implementation (on the node side; nothing left to do on the Haskell side), get a th unit test up and running. 2019-04-01 Covers last week. Ongoing work: Refactored inline-js-core / inline-js and implemented the binary IPC interface. This is a part of the work on the node side of iserv . inline-js was based on a textual IPC interface using JSON messages via readline . When writing iserv logic this proved to be an annoyance; we'd like to reuse the Message type and its Binary instance in libiserv , instead of coming up with a JSON schema for every message; also it doesn't play nice with messages with blobs. Now inline-js-core directly transmits binary IPC, and it can be backed by any backend (e.g. stdio or network). inline-js-core now supports evaluating ES6 module code containing dynamic import() s. This is critical to iserv implementation since our code generator also generates ES6 modules. Did some linker profiling and revealed that repeated serialization is a previously undiscovered bottleneck: In ahc-ld , we pick up all library archives and object files, emit a persistent \"linker state\" as a pseudo-executable, which is later read by ahc-dist to produce executable wasm/js. When no-DCE mode is on, the linker state contains data/functions in all libraries, and although we have some degree of lazy-loading, we can't lazily save things without forcing their evaluation. Thus come the extra costs. Estimated work for this week: Support evaluating static import declarations in inline-js-core , since they are included in our js stubs. If proven to be hard, we add a switch in the code generator to only emit import() s instead. Implement the iserv message handlers in node. 2019-03-25 Covers last week. Ongoing work: Implemented the linker's \"no-DCE\" mode. Dead code elimination is now optional and can be switched off via --no-gc-sections , and this is preferrable behavior for dynamic linking. Note that for regular linking in ahc-link , no-DCE mode takes considerably longer and emits a .wasm as large as 40MB. Removed all \"rewriting passes\" for code in the linker. Previously, the linker grabs a self-contained set of data/functions, perform whole-program AST rewritings for several times, then feed the output to wasm-toolkit / binaryen backend to emit real WebAssembly binaries. By removing these passes, there's a roughly 75% speedup measured in fib for no-DCE mode, around one minute from loading all archives to node compiling and running output code. Another advantage of removing those passes: there's now a lot less linker state to keep track of, thus clearing up the last mile path to fully incremental linking. Minor downsides to the linker refactorings: We used to have an \"EmitEvent\" primitive in our IR which allows embedding any Haskell string as an \"event\" and emit it when using the monadic EDSL to construct WebAssembly code. This mechanism now degraded from allowing any string to an enumerable set of events. When the linker found a function which contains a compile-time error message, it used to emit a stub function which reports that message and crashes at runtime. Now we don't emit those anymore, and when such a function is called at runtime, the compile-time error message is not reported. Other work, when the main thread stalled: Implemented the WebAssembly tail call opcodes in wasm-toolkit and the tail-calls mode in asterius, enabled with --tail-calls , tested on CI with V8 team's latest nodejs build. The tail-calls mode gets rid of trampolining during Haskell/Cmm execution. When the user is in full control of the execution platform and doesn't mind adding a V8 flag to enable tail calls, this should result in better performance. It's unsupported by the binaryen backend yet, but we managed to re-enable the binaryen relooper, which at this moment still emits better binary than our own relooper. It seems the binaryen relooper works fine only if no value is returned from any basic block. Back when we didn't roll our own relooper and didn't realize this, it was a constant source of undefined behavior and debugging nightmares. Simplified the binaryen build script to not rely on ar -M . Got rid of CPP usage and fixed a build warning on non-macOS platforms. Planned work for the week: Conclude all linker work. All performance potential for the current linker architecture is possibly squeezed out now. It's not as fast as we want, but it's easily cachable. Once we have a fully persistent linker state, we can cache and reuse it on the first TH run, so it won't take minutes to run splices. Finish the node side of iserv logic and get preliminary TH support. 2019-03-18 Covers last week. Ongoing work: Removed the memory & table sections in output wasm binaries; now we initiate wasm memory/table in js, and it's possible to transfer them across multiple asterius instances. Rationale: The wasm spec includes data/element segment sections to initialize certain ranges of the memory/table, and also separate memory/table sections to implicitly create an empty memory/table. When incrementally linking multiple compilation units, we need to take memory/table of the previous asterius instance, \"append\" some data & code while preserving previous content. This involved some unexpected debugging sessions, and we also needed to patch the in-tree binaryen library to avoid dropping the binaryen backend. Thankfully we sorted out that mess Figured out that running regular linker passes on all loaded boot library archives is incredibly slow, and it was also harder than expected to add an incremental mode. Besides regular wasm function/data, there are also other stuff in asterius compilation units like FFI marshal info, pooled error messages, etc, which used to work nicely with \"one-shot\" linking, but harder for incremental mode. A failed attempt to speed things up: use global string interning for symbols, which are central to almost every function in asterius modules. Surprisingly no noticable speedup after the patch is applied, so this remains unmerged. Planned work for this week: Factor out a set of self-contained \"linker state\" and \"runtime state\" types, which are guaranteed serializable and thus easy to transfer. Memory/table was not enough, we also needed to take care of things like JSFFI imports/exports, SPT, eventlogs, error message pools, etc. Generate both \"vanilla\" and \"dynamic\" ways of wasm code in asterius object files. The \"dynamic\" code should already be wasm binaries without requiring whole-program rewriting passes, and we also include a custom section with symbol locations in the binary, so only a fast link-time relocating pass is required when loading a \"dynamic\" way wasm binary. 2019-03-10 Covers this week. Ongoing work: About the iserv experiment: Started implementing ahc-iserv , which is capable of receiving messages from the host ghc process. Originally, GHC compiles TH splices to bytecode and sends them to iserv . Given we don't support bytecode (yet), we hacked on that direction a little bit, and now we can compile splices to wasm modules using our regular cmm to wasm functionality. Updated ghc again, and included several new packages into the boot libs: filepath / time / unix / directory / ghc-boot / ghc-heap / ghci . A lot of functionalities in these packages won't work yet, they exist to support ghci , which includes necessary code to run TH and communicate with the host ghc process. Miscellaneous other improvements: Implemented more accurate dependency analysis for JSFFI. Previously, whenever something in a module was included in linker output, all JSFFI info of that module is also included, resulting in potentially bloated wasm import section and generated wrapper js module. Now the output wasm code and wrapper js modules are even slimmer. Removed the legacy AsteriusStore type and related logic from the linker. It was a combination of two mappings: from symbols to module names and from module names to lazily loaded modules. It was closely related to the legacy \"object store\" mechanism which stores wasm objects elsewhere and doesn't respect ghc's object output path, and since we fixed that for Cabal support, it's time to pull this weed and simplify things. The linker now solely operates on the AsteriusModule type. Implemented lazier deserialization for AsteriusModule . Now when loading a wasm object, we defer the deserialization of individual entities(data segments or functions) until they're actually included into the output module. Compared to the old module-level lazy loading mechanism, there's no noticable increase on memory usage. Optimized the code of dependency analysis. Enabled the binaryen backend to output wasm name section in debug mode. Previously, when wasm execution traps, V8 would output a stack trace, with only function ids for wasm functions. Now we spare the trouble of reading the linker report and remapping ids to function names when debugging. Note that the wasm-toolkit backend doesn't handle the name section yet. Planned work for next week: The plumbings from ahc to ahc-iserv are ready, now we need to implement an eval server running on node and the RPC logic between it and ahc-iserv . The eval server should be capable of: Initializing rts state Receiving a wasm module from ahc-iserv and remapping existing wasm memory and table Running a splice, sending serialized results to ahc-iserv Sending necessary ghc queries when running splices The requirements listed above also implies that we need to finish the linker's incremental mode first. The runtime also needs to support: Interleaved static/non-static memory regions, and reserving an address range for data segments in new incoming wasm modules Minimal Haskell exception handling support, so we can reply a QFail in ahc-iserv correctly when an exception is thrown instead of silently dying. (Informative error messages which include information recovered from Show instance of SomeException are harder to implement) 2019-03-04 Covers last week. Completed work: Thorough refactorings in the linker to improve performance & modularity. The linker used to produce small code faithfully, but the speed was slow. Moreover, the code was quite messy, with multiple pieces of whole-program traversal code scattered across a single module. In order to deliver TH support, we need the linker to be: Fast, loading archives & objects and performing all necessary rewriting passes quickly. Most likely the expensive dead code elimination optimization will hurt us in this scenario and we need a switch to disable it. Incremental. Loading some new object code into the linker state must not trigger expensive re-compilation of old code. We tidied up the linker code, moved each rewriting pass to a separate module and fused them into a single pipeline. The fusion guarantees that after dependency analysis, the AST is only traversed once to perform all necessary rewritings and produce executable wasm code. Updated ghc and standard libraries to a recent revision ( 8.7.20190217 -> 8.9.20190301 ). This includes Moritz Angermann's work to improve iserv . Planned work for the week: Start experimenting with iserv stuff. Continue working to improve the linker: The linker code now has some space for adding incremental linking logic. Whether/how it works for TH depends on more knowledge accumulated from iserv experiments. Besides rewriting passes, another major performance bottleneck is dependency analysis, where we start from a global \"store\" and root symbols to scrap a self-contained module. We'll deal with this one for this week. For TH, we'll explore the possibility of adding a switch for faster linking & larger output code. All rewriting passes for non-debug mode are migrated to the new pipeline, but two additional passes for debug mode are left untouched for now: \"memory traps\" & \"tracing\". They are tricky to get right in the new framework, and given debug mode doesn't impact regular users, these two may be left as they are for a bit more time. 2019-02-22 Covers this week. Completed work: Finished preliminary Cabal support. The executable targets are implemented. It's possible to call ahc --make directly or via ahc-cabal new-build to get an \"executable\". The \"executable\" can be quickly converted to node/web artifacts by ahc-dist . ahc-cabal is a simple wrapper of cabal . stack is possibly also supported if we provide the same configure flags. Might worth a try in the future. Cabal tests/benchmarks/documentation is not implemented yet. haddock won't work yet. Tests/benchmarks should build fine like normal executables, but Cabal can't run them like vanilla executables yet. The executables can still be \"run\" with ahc-dist --run . ahc-dist works similarly like the legacy ahc-link tool. They share most command line arguments, except ahc-dist expects --input-exe ; it starts from executable files, where ahc-link starts from Haskell sources. Third-party contributions: Thanks to Piotr Majkrzak(@majkrzak) for a PR fixing a --browser problem (#73), and issue #70 for reducing Docker image size, #74 for simplifying export module interface. Planned work for next week: Start working on Template Haskell/GHCi/Plugins (#54). This is the last major planned feature of 2019 Q1. Other potential work, in case my main thread become stalled like it always did in the past: Easy improvements in gc, e.g. adding stats. Experiment on creating a more asynchronous runtime. A relevant issue will be added shortly. 2019-02-18 Covers last week. Completed work, mainly routine maintainence: Updated ghc and standard libraries to a recent revision ( 8.7.20181115 -> 8.7.20190217 ) Updated binaryen and wabt toolchains Added the experimental bulk memory opcodes in the binaryen Haskell bindings Ongoing work: Finished implementation of library targets for Cabal. The ahc executable was only meant to be invoked from the boot script. Now it can be run to compile any user input Haskell/Cmm code and produce object files. ahc-ar is implemented to generate .a static libs, and those libs contain symbol indices required by asterius linker. The static libs can later be used as linker inputs. Currently, no patching to Cabal is required. Planned work for this week: Finish implementation of executable targets for Cabal. When compiling the \"executable\" targets, final linking (including any necessary LTO & rewriting passes) is done. The resulting file can be quickly converted to node/web artifacts by an external tool. The legacy mechanism for storing/retrieving wasm objects will be removed, and we'll only rely on the static libs and input object files for linking. Add unit tests for compiling & running stuff via cabal-install . Some improvements in gc, if we manage to finish Cabal stuff. 2019-02-11 Covers last week. Completed work: Fixed known regressions of GC & released the initial version. Additional known drawbacks of the initial version (see report of previous week): There is currently no runtime logs/stats about garbage collection. There is currently no tunable parameters; at least we should allow specifying when \"real\" gc happens and when we just allocate a new nursery instead of traversing the heap (e.g. \"real\" gc happens when the live semispace size grows beyond a threshold) StgTSO / StgStack objects are unnecessarily pinned to simplify scheduler implementation a bit, but they really should be unpinned. Planned work for this week: Start working on Cabal support. Some easy improvements in gc, e.g. adding stats/logs, implementing parameters. 2019-02-04 Covers last week. Ongoing work: Finished the preliminary implementation of GC. To increase reliability and catch regressions, after each GC pass, the recycled space is zeroed. If the tospace still contains pointers to recycled space (which is definitely a bug), the program is likely to crash early. This has helped us to identify & fix a few bugs in the GC implementation. Right now there is only one regression left: the todomvc example crashes after initial loading completes. The crash goes away if we don't zero recycled space, but it's not a good idea to just turn that off and pretend there's no bug! Remaining work for GC: Fix the todomvc regression. Given GC is such a critical component in the runtime, it's probably also good timing to integrate some more unit tests from the GHC test suite. This also needs some improvement in our debugging infrastructure: our memory traps (wasm read/write barriers) is currently unaware of recycled/live space, and now we should make it cooperate with the allocator to catch invalid access to recycled space earlier. Known drawbacks of current GC implementation once it's fully fixed & merged: No generational GC yet, so high GC overhead if a large volume of long-lived data is retained through program execution. Heap fragmentation is more severe when allocating a lot of small pinned objects. Weak# support is expected to split into two different stages and will land after initial GC merge: Support for running \"C finalizers\" added by the addCFinalizerToWeak# primop. Here, the \"C finalizers\" are really just JavaScript functions, and the \"function pointers\" are JavaScript references. Support for running arbitrary IO action as finalizers. This task requires support for Haskell multi-threading, and given multi-threading is not a scheduled goal of 2019 Q1, this will come later. Haskell closures exported to JavaScript using makeHaskellCallback* cannot be automatically recycled when they aren't used anymore. This is due to JavaScript's lacking of finalizers; users will need to call freeHaskellCallback* by hand to prevent leaking on the Haskell side. We'll yield to Cabal support & TH/GHCi/Plugins support after the first version of GC is delivered. There's definitely room for improvement later (e.g. reduce heap fragmentation, different GC algorithms for different workloads, more detailed GC statistics, etc), but those will be managed by separate tickets. 2019-01-28 Covers last week. Ongoing work: More work to improve the sanity checker and get GC near completion: The sanity checker spotted a fatal situation where previously unreachable static closures become reachable again. More experiments in this direction invalidated a previous conjecture that no special treatments for static closure is required as long as they have valid block descriptors and can be moved just like dynamic ones. The solution to the problem above is not hard: when scanning an info table, we also follow the SRT if it's present, and we still need to identify static/dynamic closures and prevent moving static ones. This is implemented in the sanity checker. The sanity checker is no longer backed by explicit recursion. When scanning a long chain of closures, we won't run out of JavaScript stack space. Adjusting the codegen & standard libraries to cope with upcoming GC: The makeHaskellCallback* interfaces now properly allocate a stable pointer for the exported Haskell closure. This is to ensure that they remain valid when later called from JavaScript, even after GC runs. The function closures of foreign export javascript clauses are recognized and become GC roots for similar reasons. Asterius.Types is moved from ghc-prim to base , so the JSVal type can be backed by StablePtr . The GC will use a tag bit to identify regular stable pointers and JavaScript references, and automatically free unused references. Integer is promoted to a standalone datatype, so the GC can scan reachable Integer s and free unreachable ones which point to BigInt s. Remaining work for GC: Implement evac/scav functionality. Implement support for Weak# s based on the constraint that no Haskell execution is required when firing a finalizer. 2019-01-21 Covers last week. Ongoing work: Bugfixes & partially done GC work of later stages (recycling Haskell heap space & JavaScript references): Unified treatment of regular StablePtr# s and JSVal in the runtime. They are identified by a tag bit, and GC will be able to recognize live JSVal s when scanning the Haskell heap. Added the SPT as sanity check/garbage collection roots. Fixed a sanity check bug related to AP/PAP heap objects. This could be triggered when checking the SPT after passing a closure built by chained rts_apply calls to rts_evalStableIO . Reimplemented the linker layout code. We now put non-closures & closures to separate regions, and the regions are statically allocated block groups which is handled by the sm uniformly like dynamically allocated groups. This enables us to treat static closures as if they're dynamic ones without any special hack. Simplified the block allocator. We no longer manage block at 4K granularity; now we only manage 1M sized ones. Pros & cons: Much fewer blocks needed to manage, so simpler/faster runtime code. Larger nurseries mean the Haskell mutator code signals HeapOverflow much less frequently. Should reduce amortized GC cost. The main drawback is increated heap fragmentation when it comes to allocating lots of small pinned objects. This is not yet a primary concern, and can be addressed later by a hybrid GC which switches to non-moving mark-sweep algorithm for block groups with pinned objects. Added functionality to free block groups, so they can later be reused without growing the linear memory. Their payloads can be zeroed to eliminate a potential attack surface (or for better reproduction of bugs in case something goes wrong) Moved allocate* to the JavaScript runtime and properly implemented allocatePinned . Previously it was simply an alias of allocate since we didn't move anything around. Planned work for next week: Wrap up all GC work and get a fully functional GC up & running. This was originally planned to finish by end of last week, but fell behind schedule due to the hidden workload described above. Required work: Implement evac/scav functionalities in the runtime. Remove the now obsolete symbol table exporting mechanism, and any closure required to survive all GC scans need to be explicitly present in the SPT upon startup. Remove the terrible hacks of directly coercing between GC pointers of boxed types and regular Addr# s when crossing the FFI boundary. Now we must properly pass StablePtr# s. Breaking refactorings in the current boot libs: The JSVal family of types need to be moved from ghc-prim to base (or a separate package depending on base ), since it needs to be a newtype wrapper of StablePtr which is defined in base . The Integer type gets promoted to a standalone datatype. We still use tagging to identify small Integer s and BigInt s which is managed by SPT just like other JSVal s. 2019-01-13 Covers the last week. The week before was new year vacation; happy new year everyone! Completed & ongoing work: Completed the \"modularized runtime\" refactorings. (#50) Drafted three feature roadmaps: Implement proper garbage collection (#52) Implement Cabal support (#53) Implement support for Template Haskell/GHCi/Plugins (#54) The above proposals are scheduled to be completed on 2019 Q1. Began working on GC, and finished the first stage: accurate heap objects traversal. Identify different types of data sections in object files (regular bytes/info tables/closures). The info table addresses are emitted into generated JavaScript to allow an accurate info table sanity check. Implemented runtime utils for directly manipulating the linear memory with tagged addresses. Implemented the sanity check which traverses the whole heap and visits every live object. All existing unit tests pass this check. Planned work for next week: Finish the second stage of GC support: evacuate/scavenge. See #52 for details. After this is finished, GC will be operational. Support for handling JSVal and Weak# is scheduled in later stages. Originally scheduled but lowered priority: Improving the Cloudflare worker demo. We're prioritizing more pressing issues like GC over specific use cases right now. Special thanks to Moritz Angermann (@angerman) for contributing a patch (#55) for fixing ar problem on macOS, and helping to improve macOS & cabal support, discovering a GHC bug related to tables-next-to-code (#16174). 2018-12-28 Covers the last two weeks. Completed work: Significant refactorings in the runtime. Pruned ~500 loc weed code in Asterius.Builtins without breaking tests. Enhanced the scheduler. Previously, when entering a Haskell thread, we evaluated to completion and checked the return code; if something goes wrong, we would just throw an error. Now, the scheduler is capable of handling certain scenarios like heap overflow and resuming Haskell execution. Enhanced the storage manager. Previously, the block allocator always triggered a grow_memory opcode when requesting blocks, making a lot of Array# / ByteArray# related primops rather in-efficient. Also, we allocated a huge heap (defaults to 1G) upon startup and pretended it won't run out. Now, the block allocator grows the linear memory efficiently. And the initial heap is small (4K for both the nursery and the object pool); an overflow condition automatically extends it. Implemented the \"persistent vault\" feature. Every asterius instance has a KV store called a \"vault\" which can be accessed in both Haskell/JavaScript. It can be used to transfer state across instances, so when an instance throws errors we can't handle, we can restart a new one without losing context. This is a part of the work for Cloudflare Worker showcase. Delivered a working TodoMVC example and issued a blog post. Other notable bugfixes/improvements: Fixed the dirty_MUT_VAR write barrier for MutVar# s. All non-atomic MutVar# / IORef / STRef operations now work. This is a part of the work for TodoMVC showcase. We implemented UTF8/UTF16-LE/UTF32-LE/Latin-1 encoding/decoding in the runtime. This is a part of the work for text support. The makeHaskellCallback functions are slightly more efficient by avoiding the overhead of allocating StablePtr s. On-going work not completed yet: Modularizing the runtime. Previously, the runtime is a single monolithic JavaScript script which is pasted into the output script. We'd like to split it to modules, and allow users to supply their own module to override the default behavior (evaluating Main.main once). Rationales: For users, it's much more convenient to implement custom logic via a proper module file. Especially in the Cloudflare Worker case, where we need: Fully synchronous initialization Capturing errors/rebooting a new instance It's now possible to write tests for individual pieces of the runtime. This is critical to improve the runtime's reliability. There were some pasted parts in the monolithic runtime; now we can properly reuse code. It's also convenient to inject link-time information into the runtime. We've introduced parcel into our toolchain to implement a \"bundling\" functionality: at link-time, re-generating a standalone .js file containing all the runtime modules. This is already implemented. We're gradually splitting the monolithic runtime to modules, taking care not to break stuff. Not completed; so far so good. Delivering a non-trivial Cloudflare Worker demo. We already have a trivial one working. It's trivial because it only does synchronous request -> response computation; more \"real-world\" ones will need to invoke asynchronous JavaScript computation (e.g. using Fetch API) Dealing with JavaScript asynchronous computation is not quite tolerable yet; we need to litter the code with makeHaskellCallback* , at least one such call for a JavaScript await . We currently have two potential approaches of improving user experience with async js code: Implement some CPS-based EDSL to automatically deal with callback marshaling. Implement a simple IO manager in the runtime which is capable of suspending Haskell threads when calling async js code and resuming them upon resolving/rejecting. The second one sounds much more decent, but has a high difficulty level. We'll start from the first one. Rough plans for next week: Finish the work on modularizing the runtime, document new behavior of JavaScript generation, then merge to master . Deliver a more decent Cloudflare worker demo which calls some async js code.","title":"Status reports"},{"location":"reports/#status-reports","text":"This page maintains a list of weekly status reports for the project.","title":"Status reports"},{"location":"reports/#2019-05-26","text":"Covers the past week. Completed work: Merged in the ghc-testsuite work and it now runs as a regular CircleCI job, producing a CSV report and an ASCII table listing grouped test failures. Improved the runtime error messages related to unresolved symbols. Previously, when the linker spots unresolved symbols, it still produces a self-contained wasm module, using an invalid address to replace such symbols, resulting in a cryptic unreachable error message when an execution path hits that symbol. Now, the linker dynamically injects a small data segment into the wasm module upon unresolved symbols. The data segment is a runtime error message indicating the missing symbol. At runtime, when the symbol is used, it'll now show the linker-generated error message in the stack trace. Roughly a half of broken ghc tests are due to unresolved symbols, indicating missing rts functionality. Combined with the binaryen backend's ability to emit the name section, it's now much clearer to spot when a standard library function calls some unimplemented feature. Implemented unicode primitives to make GHC.Unicode at least works for ASCII, also fixing a long-standing issue related to crashing read calls. Fixed localeEncoding in GHC.IO.Encoding.Iconv , which always return UTF-8 at the moment. Combined with the unicode primitives above, this also fixes some other base functionality, e.g. withCString , and also the non-iconv TextEncoding s. Implemented floating-point c functions to fix GHC.Float . Fixed the noDuplicate# primop, now unsafePerformIO works. Fixed getProgArgv in System.Environment . Now getProgName returns the \"program name\" generated from ahc-ld output path, and getArgs always return an empty list. This is a sensible default combination sufficient to fix some ghc tests, and we don't plan to implement a richer API to support providing argv to a compiled \"executable\" yet. Fixed foreign import ccall safe , since it's used in some places in base . Fixed the performGC -like functions in System.Mem . Fixed the threadPaused rts function, which played an essential role in creating gc safepoints. Removed support for \"sync mode\" code generation, which ensures the output entry js module performs synchronous wasm compilation/instantiation. This is hardly used and it's increasingly likely we'll need to perform async rts startup at some point. Pruned legacy rts code related to the \"vault\" feature which was a workaround back in the days when we didn't have gc. Ongoing and planned work: Fix debugBelch / errorBelch , which is used in some places in base (e.g. trace ) Implement \"top handler\" for main IO closure, which prints uncaught exception to stderr before returning. This is required by tests whose expected behavior is throwing, and we need to check their .stderr files. Fix GHC.Fingerprint , which is required by anything related to Typeable , e.g. runtime type checks. This is required by fromException to be used by the top handler. Investigate an issue in iohk's fork to add nix support: after ahc-boot finishes, ahc is failing to pick up the compiled archives.","title":"2019-05-26"},{"location":"reports/#2019-05-20","text":"Covers the last two weeks. Note that Siddharth Bhat(@bollu) joined in as a summer intern at Tweag I/O on this project. From this week on all status report entries are our collaborative efforts. Completed work: Fixed a bug in the codegen which ignored sign extension semantics when extending 8-bits/16-bits integers, resulting in wrong results of Int8# / Int16# / Word8# / Word16# related primops. Improved the monadic EDSL interface: Removed a redundant return type annotation in runEDSL calls. Supported declaring \"static\" memory regions, they can serve as static variables (as known in C-like languages) which persist across function calls. Updated binaryen and wabt . For binaryen , we: Spotted and worked around a minor problem: by default the validate function in C API implicitly sets the feature set to \"All\", enabling all wasm experimental features and causing the DataCount section to be emitted to wasm binary, which is unsupported in some old versions of V8. Implemented color API & s-expression API in C bindings, to support dumping s-expression of wasm to file. These two changes are also proposed to upstream. Tracked down the source of an old bug related to read crashing due to missing Unicode primitives in the runtime. Improved Cmm IR dumps to ease debugging. Many source comments; improved docs, with a new \"hacking\" section describing common workflow on hacking this project. Ongoing work and planned work: Integrate a part of ghc testsuite to run with asterius, collect the results into a report. Motivation: other than missing TH support that we're still stuck with, there are still other missing or broken features that we might be unaware of. To push asterius towards production-grade quality, we need a more comprehensive test suite to help us discover such edge cases. The single-module compile_and_run tests are copied from ghc tree, and we implemented a tasty driver to run them. Reusing the original Python-based test driver takes more work and we decide it's less of a priority at the moment. Roughly ~800 tests are included, and about 50% of them are failing at the moment. Remaining work: serve the report file as CircleCI artifact, merge back to master and start classifying the failed tests. Improve the debugging experience: Recovered the \"memory trap\" framework which we unfortunately dropped previously when attempting to get rid of link-time rewriting passes and make the linker faster. The new memory trap now relies on V8's experimental wasm BigInt integration feature, and covers all wasm read/write opcodes, even for builtin rts functions. Planned work for memory trap: we'll make the memory trap closely collaborate with the linker, block allocator and garbage collector, to achieve the following effects: There will be read-only/read-write regions, and we put immutable Cmm data in read-only regions to catch more potential data corruption. The recycled blocks will be marked inaccessible, any access to those blocks will trap. Basic exception handling is now implemented, the throw / catch functions in Control.Exception now work. We plan to implement a part of @bgamari's ghc gdb scripts for chrome devtools: inspecting closures and other rts data structures, walking the stack, etc.","title":"2019-05-20"},{"location":"reports/#2019-05-06","text":"Covers the paralyzed few weeks since last report. To provide some context for further discussion, here is a brief summary of our attempts since we started to implement TH support, listing the approaches and encountered obstacles: Radical refactorings to make the linker faster. Linking for TH is quite unlike linking for regular Haskell modules: we need to support dynamic loading of compiled object files and libraries, along with splices, and the linking & execution requests may be interleaved. This required the linker to rapidly process the load requests and generate working wasm/js. This part of work is done and benefits regular linking as well. Implement ahc-iserv and TH message handlers. Delegating TH logic to the iserv process enables some degree of customization on how TH requests are handled, so we can implement wasm/js linking on the host platform. This part of work is done. Implement TH running logic. This means we need to be able to start a persistent runtime, occasionally send some pieces of wasm code, and run them to retrieve serialized results (and the wasm world may call back into the host world). To smoothen Haskell/node interaction, we revived the inline-js project and added loads of new functionality to it. It works well even outside the scope of asterius. TH runner is still the roadblock: Our first attempt was trying to support incrementally loading wasm objects, running wasm code, and transfer required runtime state through some global vars. This dragged us into a long debuggathon. We're currently at the second attempt: implementing an even more naive TH runner and reducing the debugging surface. Compared to a qualified TH runner which can be shipped, the naive version: Reuses the linking logic for regular Haskell modules. Always re-links upon running a splice. Always initiates a fresh TH state to run a splice. So. Another round of debugging here. Implementing TH is a large and challenging project which already consumed much more energy than once anticipated. At this point it might be nice to adjust our strategy a bit: Keep working on TH delivery, evaluate new means of debugging (e.g. reviving the previously lost debugging tracer, using V8 inspection of node, etc) to boost the process. Since it's likely not the last time we need to perform low-level debugging, the lessons we learn here should also be recorded and help later project contributors. Spare a part of time to work on other stuff, including but not limited to: Improve the currently ad hoc test suite, start integrating ghc tests. This will give us better idea on what's currently broken and what's not. Do some housekeeping on the issue tracker. There are a few issues reported long ago but remained since TH got all the attention.","title":"2019-05-06"},{"location":"reports/#2019-04-15","text":"Covers last week. Ongoing work: Trying to use inline-js-core to run asterius compiled wasm/js. Works for: Running regular main actions and retrieving results. Calling exported rts internals to manipulate closures on the Haskell heap. Currently into a debugging rabbit hole related to getting simple expression splices to run and return serialized result: We can compile a splice of type like Q Exp , obtain the wasm closure, then use utilities from ghci to initiate a TH state and actually run it. We're hit with unreachable s at runtime; they're due to unresolved symbols substituted to an invalid address so to let linking pass, meaning there's hidden bug in the logic of either the linker itself, or how we obtain and compile the splices. Miscellaneous other improvements in inline-js . No more radical API changes are planned from now, and we have proper haddock documentation. Spread the word, give it a try in your projects too :) Estimated work for the week: Solve the runtime error related to the TH splices.","title":"2019-04-15"},{"location":"reports/#2019-04-08","text":"Covers last week. Ongoing work: Finished all required inline-js improvements to make it feasible as an iserv component. Notable changes include: The half-baked JSON implementation is removed. All JSON-related logic is now based on aeson and the higher-level inline-js package is required. We used to only pass encoded JSON messages via the IPC interface. Now we pass binary messages, and thus we can directly allocate a node Buffer from a Haskell ByteString , and return the JSVal handle to Haskell. We implemented send/receive queues and fixed a race condition related to multiple receivers to a same Transport . We switched the Haskell/ node pipes from stdin / stdout to using file descriptors. This fixes the issue when inline-js-core executes wasm/js code produced by asterius, but due to calling console API in generated code, the pipes are corrupt and leaves the ahc-iserv process in an undefined state. We investigated the issue of supporting both static/dynamic import in the eval server's input code and did a prototype using the experimental vm.SourceTextModule interface in nodejs. Conclusion: it's not worth the trouble, and although static import s aren't supported by the eval server, the issue can be worked around without major changes in the asterius js codegen. Updated ghc and fixed #98, working around a Cabal bug (#4651) impacting our Cabal support. Third-party contributions: Thanks to Stuart Geipel(@pimlu) for discovering an issue in the garbage collector and providing a minimal repro (#97). Investigation of this issue required fixing the \"memory traps\"/\"tracing\" rewriting passes previously removed in order to speed up the linker, so is currently scheduled behind ongoing TH work. Thanks to Yuji Yamamoto(@igrep) for discovering an issue in the Cabal support (#98), and an issue in the JSFFI implementation (#102). Estimated work for the week: Just finish the iserv implementation (on the node side; nothing left to do on the Haskell side), get a th unit test up and running.","title":"2019-04-08"},{"location":"reports/#2019-04-01","text":"Covers last week. Ongoing work: Refactored inline-js-core / inline-js and implemented the binary IPC interface. This is a part of the work on the node side of iserv . inline-js was based on a textual IPC interface using JSON messages via readline . When writing iserv logic this proved to be an annoyance; we'd like to reuse the Message type and its Binary instance in libiserv , instead of coming up with a JSON schema for every message; also it doesn't play nice with messages with blobs. Now inline-js-core directly transmits binary IPC, and it can be backed by any backend (e.g. stdio or network). inline-js-core now supports evaluating ES6 module code containing dynamic import() s. This is critical to iserv implementation since our code generator also generates ES6 modules. Did some linker profiling and revealed that repeated serialization is a previously undiscovered bottleneck: In ahc-ld , we pick up all library archives and object files, emit a persistent \"linker state\" as a pseudo-executable, which is later read by ahc-dist to produce executable wasm/js. When no-DCE mode is on, the linker state contains data/functions in all libraries, and although we have some degree of lazy-loading, we can't lazily save things without forcing their evaluation. Thus come the extra costs. Estimated work for this week: Support evaluating static import declarations in inline-js-core , since they are included in our js stubs. If proven to be hard, we add a switch in the code generator to only emit import() s instead. Implement the iserv message handlers in node.","title":"2019-04-01"},{"location":"reports/#2019-03-25","text":"Covers last week. Ongoing work: Implemented the linker's \"no-DCE\" mode. Dead code elimination is now optional and can be switched off via --no-gc-sections , and this is preferrable behavior for dynamic linking. Note that for regular linking in ahc-link , no-DCE mode takes considerably longer and emits a .wasm as large as 40MB. Removed all \"rewriting passes\" for code in the linker. Previously, the linker grabs a self-contained set of data/functions, perform whole-program AST rewritings for several times, then feed the output to wasm-toolkit / binaryen backend to emit real WebAssembly binaries. By removing these passes, there's a roughly 75% speedup measured in fib for no-DCE mode, around one minute from loading all archives to node compiling and running output code. Another advantage of removing those passes: there's now a lot less linker state to keep track of, thus clearing up the last mile path to fully incremental linking. Minor downsides to the linker refactorings: We used to have an \"EmitEvent\" primitive in our IR which allows embedding any Haskell string as an \"event\" and emit it when using the monadic EDSL to construct WebAssembly code. This mechanism now degraded from allowing any string to an enumerable set of events. When the linker found a function which contains a compile-time error message, it used to emit a stub function which reports that message and crashes at runtime. Now we don't emit those anymore, and when such a function is called at runtime, the compile-time error message is not reported. Other work, when the main thread stalled: Implemented the WebAssembly tail call opcodes in wasm-toolkit and the tail-calls mode in asterius, enabled with --tail-calls , tested on CI with V8 team's latest nodejs build. The tail-calls mode gets rid of trampolining during Haskell/Cmm execution. When the user is in full control of the execution platform and doesn't mind adding a V8 flag to enable tail calls, this should result in better performance. It's unsupported by the binaryen backend yet, but we managed to re-enable the binaryen relooper, which at this moment still emits better binary than our own relooper. It seems the binaryen relooper works fine only if no value is returned from any basic block. Back when we didn't roll our own relooper and didn't realize this, it was a constant source of undefined behavior and debugging nightmares. Simplified the binaryen build script to not rely on ar -M . Got rid of CPP usage and fixed a build warning on non-macOS platforms. Planned work for the week: Conclude all linker work. All performance potential for the current linker architecture is possibly squeezed out now. It's not as fast as we want, but it's easily cachable. Once we have a fully persistent linker state, we can cache and reuse it on the first TH run, so it won't take minutes to run splices. Finish the node side of iserv logic and get preliminary TH support.","title":"2019-03-25"},{"location":"reports/#2019-03-18","text":"Covers last week. Ongoing work: Removed the memory & table sections in output wasm binaries; now we initiate wasm memory/table in js, and it's possible to transfer them across multiple asterius instances. Rationale: The wasm spec includes data/element segment sections to initialize certain ranges of the memory/table, and also separate memory/table sections to implicitly create an empty memory/table. When incrementally linking multiple compilation units, we need to take memory/table of the previous asterius instance, \"append\" some data & code while preserving previous content. This involved some unexpected debugging sessions, and we also needed to patch the in-tree binaryen library to avoid dropping the binaryen backend. Thankfully we sorted out that mess Figured out that running regular linker passes on all loaded boot library archives is incredibly slow, and it was also harder than expected to add an incremental mode. Besides regular wasm function/data, there are also other stuff in asterius compilation units like FFI marshal info, pooled error messages, etc, which used to work nicely with \"one-shot\" linking, but harder for incremental mode. A failed attempt to speed things up: use global string interning for symbols, which are central to almost every function in asterius modules. Surprisingly no noticable speedup after the patch is applied, so this remains unmerged. Planned work for this week: Factor out a set of self-contained \"linker state\" and \"runtime state\" types, which are guaranteed serializable and thus easy to transfer. Memory/table was not enough, we also needed to take care of things like JSFFI imports/exports, SPT, eventlogs, error message pools, etc. Generate both \"vanilla\" and \"dynamic\" ways of wasm code in asterius object files. The \"dynamic\" code should already be wasm binaries without requiring whole-program rewriting passes, and we also include a custom section with symbol locations in the binary, so only a fast link-time relocating pass is required when loading a \"dynamic\" way wasm binary.","title":"2019-03-18"},{"location":"reports/#2019-03-10","text":"Covers this week. Ongoing work: About the iserv experiment: Started implementing ahc-iserv , which is capable of receiving messages from the host ghc process. Originally, GHC compiles TH splices to bytecode and sends them to iserv . Given we don't support bytecode (yet), we hacked on that direction a little bit, and now we can compile splices to wasm modules using our regular cmm to wasm functionality. Updated ghc again, and included several new packages into the boot libs: filepath / time / unix / directory / ghc-boot / ghc-heap / ghci . A lot of functionalities in these packages won't work yet, they exist to support ghci , which includes necessary code to run TH and communicate with the host ghc process. Miscellaneous other improvements: Implemented more accurate dependency analysis for JSFFI. Previously, whenever something in a module was included in linker output, all JSFFI info of that module is also included, resulting in potentially bloated wasm import section and generated wrapper js module. Now the output wasm code and wrapper js modules are even slimmer. Removed the legacy AsteriusStore type and related logic from the linker. It was a combination of two mappings: from symbols to module names and from module names to lazily loaded modules. It was closely related to the legacy \"object store\" mechanism which stores wasm objects elsewhere and doesn't respect ghc's object output path, and since we fixed that for Cabal support, it's time to pull this weed and simplify things. The linker now solely operates on the AsteriusModule type. Implemented lazier deserialization for AsteriusModule . Now when loading a wasm object, we defer the deserialization of individual entities(data segments or functions) until they're actually included into the output module. Compared to the old module-level lazy loading mechanism, there's no noticable increase on memory usage. Optimized the code of dependency analysis. Enabled the binaryen backend to output wasm name section in debug mode. Previously, when wasm execution traps, V8 would output a stack trace, with only function ids for wasm functions. Now we spare the trouble of reading the linker report and remapping ids to function names when debugging. Note that the wasm-toolkit backend doesn't handle the name section yet. Planned work for next week: The plumbings from ahc to ahc-iserv are ready, now we need to implement an eval server running on node and the RPC logic between it and ahc-iserv . The eval server should be capable of: Initializing rts state Receiving a wasm module from ahc-iserv and remapping existing wasm memory and table Running a splice, sending serialized results to ahc-iserv Sending necessary ghc queries when running splices The requirements listed above also implies that we need to finish the linker's incremental mode first. The runtime also needs to support: Interleaved static/non-static memory regions, and reserving an address range for data segments in new incoming wasm modules Minimal Haskell exception handling support, so we can reply a QFail in ahc-iserv correctly when an exception is thrown instead of silently dying. (Informative error messages which include information recovered from Show instance of SomeException are harder to implement)","title":"2019-03-10"},{"location":"reports/#2019-03-04","text":"Covers last week. Completed work: Thorough refactorings in the linker to improve performance & modularity. The linker used to produce small code faithfully, but the speed was slow. Moreover, the code was quite messy, with multiple pieces of whole-program traversal code scattered across a single module. In order to deliver TH support, we need the linker to be: Fast, loading archives & objects and performing all necessary rewriting passes quickly. Most likely the expensive dead code elimination optimization will hurt us in this scenario and we need a switch to disable it. Incremental. Loading some new object code into the linker state must not trigger expensive re-compilation of old code. We tidied up the linker code, moved each rewriting pass to a separate module and fused them into a single pipeline. The fusion guarantees that after dependency analysis, the AST is only traversed once to perform all necessary rewritings and produce executable wasm code. Updated ghc and standard libraries to a recent revision ( 8.7.20190217 -> 8.9.20190301 ). This includes Moritz Angermann's work to improve iserv . Planned work for the week: Start experimenting with iserv stuff. Continue working to improve the linker: The linker code now has some space for adding incremental linking logic. Whether/how it works for TH depends on more knowledge accumulated from iserv experiments. Besides rewriting passes, another major performance bottleneck is dependency analysis, where we start from a global \"store\" and root symbols to scrap a self-contained module. We'll deal with this one for this week. For TH, we'll explore the possibility of adding a switch for faster linking & larger output code. All rewriting passes for non-debug mode are migrated to the new pipeline, but two additional passes for debug mode are left untouched for now: \"memory traps\" & \"tracing\". They are tricky to get right in the new framework, and given debug mode doesn't impact regular users, these two may be left as they are for a bit more time.","title":"2019-03-04"},{"location":"reports/#2019-02-22","text":"Covers this week. Completed work: Finished preliminary Cabal support. The executable targets are implemented. It's possible to call ahc --make directly or via ahc-cabal new-build to get an \"executable\". The \"executable\" can be quickly converted to node/web artifacts by ahc-dist . ahc-cabal is a simple wrapper of cabal . stack is possibly also supported if we provide the same configure flags. Might worth a try in the future. Cabal tests/benchmarks/documentation is not implemented yet. haddock won't work yet. Tests/benchmarks should build fine like normal executables, but Cabal can't run them like vanilla executables yet. The executables can still be \"run\" with ahc-dist --run . ahc-dist works similarly like the legacy ahc-link tool. They share most command line arguments, except ahc-dist expects --input-exe ; it starts from executable files, where ahc-link starts from Haskell sources. Third-party contributions: Thanks to Piotr Majkrzak(@majkrzak) for a PR fixing a --browser problem (#73), and issue #70 for reducing Docker image size, #74 for simplifying export module interface. Planned work for next week: Start working on Template Haskell/GHCi/Plugins (#54). This is the last major planned feature of 2019 Q1. Other potential work, in case my main thread become stalled like it always did in the past: Easy improvements in gc, e.g. adding stats. Experiment on creating a more asynchronous runtime. A relevant issue will be added shortly.","title":"2019-02-22"},{"location":"reports/#2019-02-18","text":"Covers last week. Completed work, mainly routine maintainence: Updated ghc and standard libraries to a recent revision ( 8.7.20181115 -> 8.7.20190217 ) Updated binaryen and wabt toolchains Added the experimental bulk memory opcodes in the binaryen Haskell bindings Ongoing work: Finished implementation of library targets for Cabal. The ahc executable was only meant to be invoked from the boot script. Now it can be run to compile any user input Haskell/Cmm code and produce object files. ahc-ar is implemented to generate .a static libs, and those libs contain symbol indices required by asterius linker. The static libs can later be used as linker inputs. Currently, no patching to Cabal is required. Planned work for this week: Finish implementation of executable targets for Cabal. When compiling the \"executable\" targets, final linking (including any necessary LTO & rewriting passes) is done. The resulting file can be quickly converted to node/web artifacts by an external tool. The legacy mechanism for storing/retrieving wasm objects will be removed, and we'll only rely on the static libs and input object files for linking. Add unit tests for compiling & running stuff via cabal-install . Some improvements in gc, if we manage to finish Cabal stuff.","title":"2019-02-18"},{"location":"reports/#2019-02-11","text":"Covers last week. Completed work: Fixed known regressions of GC & released the initial version. Additional known drawbacks of the initial version (see report of previous week): There is currently no runtime logs/stats about garbage collection. There is currently no tunable parameters; at least we should allow specifying when \"real\" gc happens and when we just allocate a new nursery instead of traversing the heap (e.g. \"real\" gc happens when the live semispace size grows beyond a threshold) StgTSO / StgStack objects are unnecessarily pinned to simplify scheduler implementation a bit, but they really should be unpinned. Planned work for this week: Start working on Cabal support. Some easy improvements in gc, e.g. adding stats/logs, implementing parameters.","title":"2019-02-11"},{"location":"reports/#2019-02-04","text":"Covers last week. Ongoing work: Finished the preliminary implementation of GC. To increase reliability and catch regressions, after each GC pass, the recycled space is zeroed. If the tospace still contains pointers to recycled space (which is definitely a bug), the program is likely to crash early. This has helped us to identify & fix a few bugs in the GC implementation. Right now there is only one regression left: the todomvc example crashes after initial loading completes. The crash goes away if we don't zero recycled space, but it's not a good idea to just turn that off and pretend there's no bug! Remaining work for GC: Fix the todomvc regression. Given GC is such a critical component in the runtime, it's probably also good timing to integrate some more unit tests from the GHC test suite. This also needs some improvement in our debugging infrastructure: our memory traps (wasm read/write barriers) is currently unaware of recycled/live space, and now we should make it cooperate with the allocator to catch invalid access to recycled space earlier. Known drawbacks of current GC implementation once it's fully fixed & merged: No generational GC yet, so high GC overhead if a large volume of long-lived data is retained through program execution. Heap fragmentation is more severe when allocating a lot of small pinned objects. Weak# support is expected to split into two different stages and will land after initial GC merge: Support for running \"C finalizers\" added by the addCFinalizerToWeak# primop. Here, the \"C finalizers\" are really just JavaScript functions, and the \"function pointers\" are JavaScript references. Support for running arbitrary IO action as finalizers. This task requires support for Haskell multi-threading, and given multi-threading is not a scheduled goal of 2019 Q1, this will come later. Haskell closures exported to JavaScript using makeHaskellCallback* cannot be automatically recycled when they aren't used anymore. This is due to JavaScript's lacking of finalizers; users will need to call freeHaskellCallback* by hand to prevent leaking on the Haskell side. We'll yield to Cabal support & TH/GHCi/Plugins support after the first version of GC is delivered. There's definitely room for improvement later (e.g. reduce heap fragmentation, different GC algorithms for different workloads, more detailed GC statistics, etc), but those will be managed by separate tickets.","title":"2019-02-04"},{"location":"reports/#2019-01-28","text":"Covers last week. Ongoing work: More work to improve the sanity checker and get GC near completion: The sanity checker spotted a fatal situation where previously unreachable static closures become reachable again. More experiments in this direction invalidated a previous conjecture that no special treatments for static closure is required as long as they have valid block descriptors and can be moved just like dynamic ones. The solution to the problem above is not hard: when scanning an info table, we also follow the SRT if it's present, and we still need to identify static/dynamic closures and prevent moving static ones. This is implemented in the sanity checker. The sanity checker is no longer backed by explicit recursion. When scanning a long chain of closures, we won't run out of JavaScript stack space. Adjusting the codegen & standard libraries to cope with upcoming GC: The makeHaskellCallback* interfaces now properly allocate a stable pointer for the exported Haskell closure. This is to ensure that they remain valid when later called from JavaScript, even after GC runs. The function closures of foreign export javascript clauses are recognized and become GC roots for similar reasons. Asterius.Types is moved from ghc-prim to base , so the JSVal type can be backed by StablePtr . The GC will use a tag bit to identify regular stable pointers and JavaScript references, and automatically free unused references. Integer is promoted to a standalone datatype, so the GC can scan reachable Integer s and free unreachable ones which point to BigInt s. Remaining work for GC: Implement evac/scav functionality. Implement support for Weak# s based on the constraint that no Haskell execution is required when firing a finalizer.","title":"2019-01-28"},{"location":"reports/#2019-01-21","text":"Covers last week. Ongoing work: Bugfixes & partially done GC work of later stages (recycling Haskell heap space & JavaScript references): Unified treatment of regular StablePtr# s and JSVal in the runtime. They are identified by a tag bit, and GC will be able to recognize live JSVal s when scanning the Haskell heap. Added the SPT as sanity check/garbage collection roots. Fixed a sanity check bug related to AP/PAP heap objects. This could be triggered when checking the SPT after passing a closure built by chained rts_apply calls to rts_evalStableIO . Reimplemented the linker layout code. We now put non-closures & closures to separate regions, and the regions are statically allocated block groups which is handled by the sm uniformly like dynamically allocated groups. This enables us to treat static closures as if they're dynamic ones without any special hack. Simplified the block allocator. We no longer manage block at 4K granularity; now we only manage 1M sized ones. Pros & cons: Much fewer blocks needed to manage, so simpler/faster runtime code. Larger nurseries mean the Haskell mutator code signals HeapOverflow much less frequently. Should reduce amortized GC cost. The main drawback is increated heap fragmentation when it comes to allocating lots of small pinned objects. This is not yet a primary concern, and can be addressed later by a hybrid GC which switches to non-moving mark-sweep algorithm for block groups with pinned objects. Added functionality to free block groups, so they can later be reused without growing the linear memory. Their payloads can be zeroed to eliminate a potential attack surface (or for better reproduction of bugs in case something goes wrong) Moved allocate* to the JavaScript runtime and properly implemented allocatePinned . Previously it was simply an alias of allocate since we didn't move anything around. Planned work for next week: Wrap up all GC work and get a fully functional GC up & running. This was originally planned to finish by end of last week, but fell behind schedule due to the hidden workload described above. Required work: Implement evac/scav functionalities in the runtime. Remove the now obsolete symbol table exporting mechanism, and any closure required to survive all GC scans need to be explicitly present in the SPT upon startup. Remove the terrible hacks of directly coercing between GC pointers of boxed types and regular Addr# s when crossing the FFI boundary. Now we must properly pass StablePtr# s. Breaking refactorings in the current boot libs: The JSVal family of types need to be moved from ghc-prim to base (or a separate package depending on base ), since it needs to be a newtype wrapper of StablePtr which is defined in base . The Integer type gets promoted to a standalone datatype. We still use tagging to identify small Integer s and BigInt s which is managed by SPT just like other JSVal s.","title":"2019-01-21"},{"location":"reports/#2019-01-13","text":"Covers the last week. The week before was new year vacation; happy new year everyone! Completed & ongoing work: Completed the \"modularized runtime\" refactorings. (#50) Drafted three feature roadmaps: Implement proper garbage collection (#52) Implement Cabal support (#53) Implement support for Template Haskell/GHCi/Plugins (#54) The above proposals are scheduled to be completed on 2019 Q1. Began working on GC, and finished the first stage: accurate heap objects traversal. Identify different types of data sections in object files (regular bytes/info tables/closures). The info table addresses are emitted into generated JavaScript to allow an accurate info table sanity check. Implemented runtime utils for directly manipulating the linear memory with tagged addresses. Implemented the sanity check which traverses the whole heap and visits every live object. All existing unit tests pass this check. Planned work for next week: Finish the second stage of GC support: evacuate/scavenge. See #52 for details. After this is finished, GC will be operational. Support for handling JSVal and Weak# is scheduled in later stages. Originally scheduled but lowered priority: Improving the Cloudflare worker demo. We're prioritizing more pressing issues like GC over specific use cases right now. Special thanks to Moritz Angermann (@angerman) for contributing a patch (#55) for fixing ar problem on macOS, and helping to improve macOS & cabal support, discovering a GHC bug related to tables-next-to-code (#16174).","title":"2019-01-13"},{"location":"reports/#2018-12-28","text":"Covers the last two weeks. Completed work: Significant refactorings in the runtime. Pruned ~500 loc weed code in Asterius.Builtins without breaking tests. Enhanced the scheduler. Previously, when entering a Haskell thread, we evaluated to completion and checked the return code; if something goes wrong, we would just throw an error. Now, the scheduler is capable of handling certain scenarios like heap overflow and resuming Haskell execution. Enhanced the storage manager. Previously, the block allocator always triggered a grow_memory opcode when requesting blocks, making a lot of Array# / ByteArray# related primops rather in-efficient. Also, we allocated a huge heap (defaults to 1G) upon startup and pretended it won't run out. Now, the block allocator grows the linear memory efficiently. And the initial heap is small (4K for both the nursery and the object pool); an overflow condition automatically extends it. Implemented the \"persistent vault\" feature. Every asterius instance has a KV store called a \"vault\" which can be accessed in both Haskell/JavaScript. It can be used to transfer state across instances, so when an instance throws errors we can't handle, we can restart a new one without losing context. This is a part of the work for Cloudflare Worker showcase. Delivered a working TodoMVC example and issued a blog post. Other notable bugfixes/improvements: Fixed the dirty_MUT_VAR write barrier for MutVar# s. All non-atomic MutVar# / IORef / STRef operations now work. This is a part of the work for TodoMVC showcase. We implemented UTF8/UTF16-LE/UTF32-LE/Latin-1 encoding/decoding in the runtime. This is a part of the work for text support. The makeHaskellCallback functions are slightly more efficient by avoiding the overhead of allocating StablePtr s. On-going work not completed yet: Modularizing the runtime. Previously, the runtime is a single monolithic JavaScript script which is pasted into the output script. We'd like to split it to modules, and allow users to supply their own module to override the default behavior (evaluating Main.main once). Rationales: For users, it's much more convenient to implement custom logic via a proper module file. Especially in the Cloudflare Worker case, where we need: Fully synchronous initialization Capturing errors/rebooting a new instance It's now possible to write tests for individual pieces of the runtime. This is critical to improve the runtime's reliability. There were some pasted parts in the monolithic runtime; now we can properly reuse code. It's also convenient to inject link-time information into the runtime. We've introduced parcel into our toolchain to implement a \"bundling\" functionality: at link-time, re-generating a standalone .js file containing all the runtime modules. This is already implemented. We're gradually splitting the monolithic runtime to modules, taking care not to break stuff. Not completed; so far so good. Delivering a non-trivial Cloudflare Worker demo. We already have a trivial one working. It's trivial because it only does synchronous request -> response computation; more \"real-world\" ones will need to invoke asynchronous JavaScript computation (e.g. using Fetch API) Dealing with JavaScript asynchronous computation is not quite tolerable yet; we need to litter the code with makeHaskellCallback* , at least one such call for a JavaScript await . We currently have two potential approaches of improving user experience with async js code: Implement some CPS-based EDSL to automatically deal with callback marshaling. Implement a simple IO manager in the runtime which is capable of suspending Haskell threads when calling async js code and resuming them upon resolving/rejecting. The second one sounds much more decent, but has a high difficulty level. We'll start from the first one. Rough plans for next week: Finish the work on modularizing the runtime, document new behavior of JavaScript generation, then merge to master . Deliver a more decent Cloudflare worker demo which calls some async js code.","title":"2018-12-28"},{"location":"rts-api/","text":"Invoking RTS API in JavaScript For the brave souls who prefer to play with raw pointers instead of syntactic sugar, it's possible to invoke RTS API directly in JavaScript. This grants us the ability to: Allocate memory, create and inspect Haskell closures on the heap. Trigger Haskell evaluation, then retrieve the results back into JavaScript. Use raw Cmm symbols to summon any function, not limited to the \"foreign exported\" ones. Here is a simple example. Suppose we have a Main.fact function: fact :: Int -> Int fact 0 = 1 fact n = n * fact (n - 1) The first step is ensuring fact is actually contained in the final WebAssembly binary produced by ahc-link . ahc-link performs aggressive dead-code elimination (or more precisely, live-code discovery) by starting from a set of \"root symbols\" (usually Main_main_closure which corresponds to Main.main ), repeatedly traversing ASTs and including any discovered symbols. So if Main.main does not have a transitive dependency on fact , fact won't be included into the binary. In order to include fact , either use it in some way in main , or supply --extra-root-symbol=Main_fact_closure flag to ahc-link when compiling. The next step is locating the pointer of fact . The \"asterius instance\" type we mentioned before contains two \"symbol map\" fields: staticsSymbolMap maps static data symbols to linear memory absolute addresses, and functionSymbolMap maps function symbols to WebAssembly function table indices. In this case, we can use i.staticsSymbolMap.Main_fact_closure as the pointer value of Main_fact_closure . For a Haskell top-level function, there're also pointers to the info table/entry function, but we don't need those two in this example. Since we'd like to call fact , we need to apply it to an argument, build a thunk representing the result, then evaluate the thunk to WHNF and retrieve the result. Assuming we're passing --asterius-instance-callback=i=>{ ... } to ahc-link , in the callback body, we can use RTS API like this: i.wasmInstance.exports.hs_init(); const argument = i.wasmInstance.exports.rts_mkInt(5); const thunk = i.wasmInstance.exports.rts_apply(i.staticsSymbolMap.Main_fact_closure, argument); const tid = i.wasmInstance.exports.rts_eval(thunk); console.log(i.wasmInstance.exports.rts_getInt(i.wasmInstance.exports.getTSOret(tid))); A line-by-line explanation follows: As usual, the first step is calling hs_init to initialize the runtime. Assuming we'd like to calculate fact 5 , we need to build an Int object which value is 5 . We can't directly pass the JavaScript 5 , instead we should call rts_mkInt , which properly allocates a heap object and sets up the info pointer of an Int value. When we need to pass a value of basic type (e.g. Int , StablePtr , etc), we should always call rts_mk* and use the returned pointers to the allocated heap object. Then we can apply fact to 5 by using rts_apply . It builds a thunk without triggering evaluation. If we are dealing with a curried multiple-arguments function, we should chain rts_apply repeatedly until we get a thunk representing the final result. Finally, we call rts_eval , which enters the runtime and perform all the evaluation for us. There are different types of evaluation functions: rts_eval evaluates a thunk of type a to WHNF. rts_evalIO evaluates the result of IO a to WHNF. rts_evalLazyIO evaluates IO a , without forcing the result to WHNF. It is also the default evaluator used by the runtime to run Main.main . All rts_eval* functions initiate a new Haskell thread for evaluation, and they return a thread ID. The thread ID is useful for inspecting whether or not evaluation succeeded and what the result is. If we need to retrieve the result back to JavaScript, we must pick an evaluator function which forces the result to WHNF. The rts_get* functions assume the objects are evaluated and won't trigger evaluation. Assuming we stored the thread ID to tid , we can use getTSOret(tid) to retrieve the result. The result is always a pointer to the Haskell heap, so additionally we need to use rts_getInt to retrieve the unboxed Int content to JavaScript. Most users probably don't need to use RTS API manually, since the foreign import / export syntactic sugar and the makeHaskellCallback interface should be sufficient for typical use cases of Haskell/JavaScript interaction. Though it won't hurt to know what is hidden beneath the syntactic sugar, foreign import / export is implemented by automatically generating stub WebAssembly functions which calls RTS API for you.","title":"Invoking RTS API in JavaScript"},{"location":"rts-api/#invoking-rts-api-in-javascript","text":"For the brave souls who prefer to play with raw pointers instead of syntactic sugar, it's possible to invoke RTS API directly in JavaScript. This grants us the ability to: Allocate memory, create and inspect Haskell closures on the heap. Trigger Haskell evaluation, then retrieve the results back into JavaScript. Use raw Cmm symbols to summon any function, not limited to the \"foreign exported\" ones. Here is a simple example. Suppose we have a Main.fact function: fact :: Int -> Int fact 0 = 1 fact n = n * fact (n - 1) The first step is ensuring fact is actually contained in the final WebAssembly binary produced by ahc-link . ahc-link performs aggressive dead-code elimination (or more precisely, live-code discovery) by starting from a set of \"root symbols\" (usually Main_main_closure which corresponds to Main.main ), repeatedly traversing ASTs and including any discovered symbols. So if Main.main does not have a transitive dependency on fact , fact won't be included into the binary. In order to include fact , either use it in some way in main , or supply --extra-root-symbol=Main_fact_closure flag to ahc-link when compiling. The next step is locating the pointer of fact . The \"asterius instance\" type we mentioned before contains two \"symbol map\" fields: staticsSymbolMap maps static data symbols to linear memory absolute addresses, and functionSymbolMap maps function symbols to WebAssembly function table indices. In this case, we can use i.staticsSymbolMap.Main_fact_closure as the pointer value of Main_fact_closure . For a Haskell top-level function, there're also pointers to the info table/entry function, but we don't need those two in this example. Since we'd like to call fact , we need to apply it to an argument, build a thunk representing the result, then evaluate the thunk to WHNF and retrieve the result. Assuming we're passing --asterius-instance-callback=i=>{ ... } to ahc-link , in the callback body, we can use RTS API like this: i.wasmInstance.exports.hs_init(); const argument = i.wasmInstance.exports.rts_mkInt(5); const thunk = i.wasmInstance.exports.rts_apply(i.staticsSymbolMap.Main_fact_closure, argument); const tid = i.wasmInstance.exports.rts_eval(thunk); console.log(i.wasmInstance.exports.rts_getInt(i.wasmInstance.exports.getTSOret(tid))); A line-by-line explanation follows: As usual, the first step is calling hs_init to initialize the runtime. Assuming we'd like to calculate fact 5 , we need to build an Int object which value is 5 . We can't directly pass the JavaScript 5 , instead we should call rts_mkInt , which properly allocates a heap object and sets up the info pointer of an Int value. When we need to pass a value of basic type (e.g. Int , StablePtr , etc), we should always call rts_mk* and use the returned pointers to the allocated heap object. Then we can apply fact to 5 by using rts_apply . It builds a thunk without triggering evaluation. If we are dealing with a curried multiple-arguments function, we should chain rts_apply repeatedly until we get a thunk representing the final result. Finally, we call rts_eval , which enters the runtime and perform all the evaluation for us. There are different types of evaluation functions: rts_eval evaluates a thunk of type a to WHNF. rts_evalIO evaluates the result of IO a to WHNF. rts_evalLazyIO evaluates IO a , without forcing the result to WHNF. It is also the default evaluator used by the runtime to run Main.main . All rts_eval* functions initiate a new Haskell thread for evaluation, and they return a thread ID. The thread ID is useful for inspecting whether or not evaluation succeeded and what the result is. If we need to retrieve the result back to JavaScript, we must pick an evaluator function which forces the result to WHNF. The rts_get* functions assume the objects are evaluated and won't trigger evaluation. Assuming we stored the thread ID to tid , we can use getTSOret(tid) to retrieve the result. The result is always a pointer to the Haskell heap, so additionally we need to use rts_getInt to retrieve the unboxed Int content to JavaScript. Most users probably don't need to use RTS API manually, since the foreign import / export syntactic sugar and the makeHaskellCallback interface should be sufficient for typical use cases of Haskell/JavaScript interaction. Though it won't hurt to know what is hidden beneath the syntactic sugar, foreign import / export is implemented by automatically generating stub WebAssembly functions which calls RTS API for you.","title":"Invoking RTS API in JavaScript"},{"location":"th/","text":"Template Haskell implementation in asterius ahc ahc is our ghc wrapper, and can be called directly or via Cabal to produce library archives and executables. Loading the frontend plugin The entry point of ahc is Language.Haskell.GHC.Toolkit.FakeGHC.fakeGHC . It takes a FrontendPlugin and generates the main function of a ghc wrapper. When the wrapper is called with --make , it does its own command-line argument parsing, then the frontend plugin does the rest. Otherwise it just calls the real ghc with the same arguments. ghc supports loading frontend plugins as a major mode, but we don't use that since it used to cause cryptic boot failures, when ghc confuses the frontend plugin's pkgdb with the wasm pkgdb. The frontend plugin Asterius.FrontendPlugin contains the main ahc logic. We use a few hooks here, and the ones relevant to wasm compilation are: cmmToRawCmmHook : We obtain raw Cmm as the starting point of wasm codegen. This hook is only used for regular Haskell/Cmm sources, not splices. runPhaseHook : We modify the pipeline for compiling a single source file. hscCompileCoreExprHook : We modify the logic of \"compiling the CoreExpr of a single TH splice and returning its foreign ref\". For TH splices, each splice's desugar output is sent to hscCompileCoreExprHook . Compiling CoreExpr of splices Asterius.Iserv.CompileCoreExpr.compileCoreExpr contains the logic of compiling splices to wasm. It generates a unique module/binder name, goes through the pipeline of Core/STG/Cmm/Wasm. In the end, we obtain a AsteriusModule which is the in-memory wasm object of the splice, and the object surely references back into the template-haskell package. When we have the wasm object, we send it to ahc-iserv via a CreateBCOs message (it's not really BCO though). ahc-iserv stores the object and returns an HValueRef which later can be used in a RunTH message. ahc-iserv ahc-iserv is the iserv process of asterius. It's managed by an ahc process. Handling TH messages Asterius.Iserv.Run.run is the main entry of ahc-iserv , implementing handlers for a subset of TH messages. run also takes a piece of IservState which is initialized when the ahc-iserv process is started. IservState IservState is defined in Asterius.Iserv.State and contains two parts: one is the session state we communicate with node , the other is the modules loaded so far. The session state is JSSession in the inline-js-core package. It manages a node process, and we can send JavaScript code to node , evaluate it, exchange binary data, etc. The loaded modules come from 3 different TH messages: LoadLibrary / LoadObj / CreateBCOs . When receiving a LoadLibrary / LoadObj message, we read the archive/object file, deserialize it and store it in the state, no linking is performed yet. The objects are indexed by filepaths and thus can be removed upon UnloadObj , but archives are combined since there isn't UnloadLibrary . CreateBCOs contains the serialized AsteriusModule for splices. It's also stored in the session state for later linking/executing. Linking for TH When handling a RunTH message, the first thing we do is linking: starting from the splice's closure symbol indexed by the HValueRef returned earlier, we obtain a self-contained AsteriusModule . This linking process reuses the linking logic of regular Haskell main modules. Even when we have an AsteriusModule , we can't run it yet; the wasm files are always acompanied by some js modules, some copied and some generated. So we also generate the js modules. The logic of TH linking is in Asterius.JSRun.NonMain . It implements the logic of linking for \"non-main\" entries: we aren't linking for main modules and don't have Main_main_closure , but we can specify other symbols (e.g. TH splice closure, TH runner closure, etc), and those symbols along with their deps will end up in the linker output. TH runner Besides the closures of splices, we also need TH runners which can run something like Q Exp and return the result in IO . Currently we have minimalistic TH runners in the Asterius.GHCi module in ghci boot lib. They are simple functions with a type signature like Q Exp -> IO JSArrayBuffer . To use these TH runners, we also set the runner symbol (e.g. ghci_AsteriusziGHCi_asteriusRunQExp_closure ) as a linker root symbol, then we use rts_apply to create a thunk which applies the runner to the splice. The thunk can then be forced to WHNF with rts_evalIO . The resulting JSArrayBuffer comes from the ByteString which is the result serialized via its binary instance. Then we can obtain the real underlying ArrayBuffer in JavaScript, and return it to the iserv process using inline-js-core . These runner functions always initiate a dummy TH state when running a splice. And all Quasi class methods (which calls ghcCmd to send queries back to the host ghc process) aren't implemented yet. Thus only trivial splices which don't call back into the host ghc are expected to work at the moment. Running splices Now that all components related to TH are introduced, how the splices are run shall be obvious. Upon a RunTH message, ahc-iserv combines all loaded libraries/objects along with the splice and perform linking, producing a wasm binary file and some js files in a temporary directory. It then loads the wasm/js files into a node process, creates an asterius instance, call hs_init() , then create the closure and evaluate it, finally returning the serialized result. The running logic is Asterius.Iserv.Run and Asterius.JSRun.NonMain . An extra thing worth noting: we also have a Asterius.JSRun.Main which contains similar runners capable of loading wasm/js into node using inline-js-core and retrieving \"standard output\" back to Haskell. The \"main\" runners are proven to work.","title":"Th"},{"location":"th/#template-haskell-implementation-in-asterius","text":"","title":"Template Haskell implementation in asterius"},{"location":"th/#ahc","text":"ahc is our ghc wrapper, and can be called directly or via Cabal to produce library archives and executables.","title":"ahc"},{"location":"th/#loading-the-frontend-plugin","text":"The entry point of ahc is Language.Haskell.GHC.Toolkit.FakeGHC.fakeGHC . It takes a FrontendPlugin and generates the main function of a ghc wrapper. When the wrapper is called with --make , it does its own command-line argument parsing, then the frontend plugin does the rest. Otherwise it just calls the real ghc with the same arguments. ghc supports loading frontend plugins as a major mode, but we don't use that since it used to cause cryptic boot failures, when ghc confuses the frontend plugin's pkgdb with the wasm pkgdb.","title":"Loading the frontend plugin"},{"location":"th/#the-frontend-plugin","text":"Asterius.FrontendPlugin contains the main ahc logic. We use a few hooks here, and the ones relevant to wasm compilation are: cmmToRawCmmHook : We obtain raw Cmm as the starting point of wasm codegen. This hook is only used for regular Haskell/Cmm sources, not splices. runPhaseHook : We modify the pipeline for compiling a single source file. hscCompileCoreExprHook : We modify the logic of \"compiling the CoreExpr of a single TH splice and returning its foreign ref\". For TH splices, each splice's desugar output is sent to hscCompileCoreExprHook .","title":"The frontend plugin"},{"location":"th/#compiling-coreexpr-of-splices","text":"Asterius.Iserv.CompileCoreExpr.compileCoreExpr contains the logic of compiling splices to wasm. It generates a unique module/binder name, goes through the pipeline of Core/STG/Cmm/Wasm. In the end, we obtain a AsteriusModule which is the in-memory wasm object of the splice, and the object surely references back into the template-haskell package. When we have the wasm object, we send it to ahc-iserv via a CreateBCOs message (it's not really BCO though). ahc-iserv stores the object and returns an HValueRef which later can be used in a RunTH message.","title":"Compiling CoreExpr of splices"},{"location":"th/#ahc-iserv","text":"ahc-iserv is the iserv process of asterius. It's managed by an ahc process.","title":"ahc-iserv"},{"location":"th/#handling-th-messages","text":"Asterius.Iserv.Run.run is the main entry of ahc-iserv , implementing handlers for a subset of TH messages. run also takes a piece of IservState which is initialized when the ahc-iserv process is started.","title":"Handling TH messages"},{"location":"th/#iservstate","text":"IservState is defined in Asterius.Iserv.State and contains two parts: one is the session state we communicate with node , the other is the modules loaded so far. The session state is JSSession in the inline-js-core package. It manages a node process, and we can send JavaScript code to node , evaluate it, exchange binary data, etc. The loaded modules come from 3 different TH messages: LoadLibrary / LoadObj / CreateBCOs . When receiving a LoadLibrary / LoadObj message, we read the archive/object file, deserialize it and store it in the state, no linking is performed yet. The objects are indexed by filepaths and thus can be removed upon UnloadObj , but archives are combined since there isn't UnloadLibrary . CreateBCOs contains the serialized AsteriusModule for splices. It's also stored in the session state for later linking/executing.","title":"IservState"},{"location":"th/#linking-for-th","text":"When handling a RunTH message, the first thing we do is linking: starting from the splice's closure symbol indexed by the HValueRef returned earlier, we obtain a self-contained AsteriusModule . This linking process reuses the linking logic of regular Haskell main modules. Even when we have an AsteriusModule , we can't run it yet; the wasm files are always acompanied by some js modules, some copied and some generated. So we also generate the js modules. The logic of TH linking is in Asterius.JSRun.NonMain . It implements the logic of linking for \"non-main\" entries: we aren't linking for main modules and don't have Main_main_closure , but we can specify other symbols (e.g. TH splice closure, TH runner closure, etc), and those symbols along with their deps will end up in the linker output.","title":"Linking for TH"},{"location":"th/#th-runner","text":"Besides the closures of splices, we also need TH runners which can run something like Q Exp and return the result in IO . Currently we have minimalistic TH runners in the Asterius.GHCi module in ghci boot lib. They are simple functions with a type signature like Q Exp -> IO JSArrayBuffer . To use these TH runners, we also set the runner symbol (e.g. ghci_AsteriusziGHCi_asteriusRunQExp_closure ) as a linker root symbol, then we use rts_apply to create a thunk which applies the runner to the splice. The thunk can then be forced to WHNF with rts_evalIO . The resulting JSArrayBuffer comes from the ByteString which is the result serialized via its binary instance. Then we can obtain the real underlying ArrayBuffer in JavaScript, and return it to the iserv process using inline-js-core . These runner functions always initiate a dummy TH state when running a splice. And all Quasi class methods (which calls ghcCmd to send queries back to the host ghc process) aren't implemented yet. Thus only trivial splices which don't call back into the host ghc are expected to work at the moment.","title":"TH runner"},{"location":"th/#running-splices","text":"Now that all components related to TH are introduced, how the splices are run shall be obvious. Upon a RunTH message, ahc-iserv combines all loaded libraries/objects along with the splice and perform linking, producing a wasm binary file and some js files in a temporary directory. It then loads the wasm/js files into a node process, creates an asterius instance, call hs_init() , then create the closure and evaluate it, finally returning the serialized result. The running logic is Asterius.Iserv.Run and Asterius.JSRun.NonMain . An extra thing worth noting: we also have a Asterius.JSRun.Main which contains similar runners capable of loading wasm/js into node using inline-js-core and retrieving \"standard output\" back to Haskell. The \"main\" runners are proven to work.","title":"Running splices"},{"location":"wasm-experimental/","text":"Using experimental WebAssembly features Currently, asterius only emits code that uses WebAssembly MVP features. At this moment, multiple WebAssembly feature proposals are actively being discussed and developed, and we are keeping an eye on them. The V8 team maintains a Node.js build which integrates V8 trunk, described here . It's possible to use that build to evaluate experimental WebAssembly features; we provide utils/v8-node.py which unzips the latest test-passing build to the current directory. Here is a list of V8 tracking issues of the features we are interested in. Some are already available in recent Node.js or Chromium releases. WebAssembly SIMD WebAssembly Multi-value WebAssembly nontrapping float-to-int conversions Tail call opcodes Reference types WebAssembly i64 BigInt integration WebAssembly JS Reflection API WebAssembly Bulk Memory Exception handling support Garbage Collection","title":"Using experimental WebAssembly features"},{"location":"wasm-experimental/#using-experimental-webassembly-features","text":"Currently, asterius only emits code that uses WebAssembly MVP features. At this moment, multiple WebAssembly feature proposals are actively being discussed and developed, and we are keeping an eye on them. The V8 team maintains a Node.js build which integrates V8 trunk, described here . It's possible to use that build to evaluate experimental WebAssembly features; we provide utils/v8-node.py which unzips the latest test-passing build to the current directory. Here is a list of V8 tracking issues of the features we are interested in. Some are already available in recent Node.js or Chromium releases. WebAssembly SIMD WebAssembly Multi-value WebAssembly nontrapping float-to-int conversions Tail call opcodes Reference types WebAssembly i64 BigInt integration WebAssembly JS Reflection API WebAssembly Bulk Memory Exception handling support Garbage Collection","title":"Using experimental WebAssembly features"},{"location":"wasm-in-hs/","text":"Writing WebAssembly code in Haskell In Asterius.Builtins , there are WebAssembly shims which serve as our runtime. We choose to write WebAssembly code in Haskell, using Haskell as our familiar meta-language. As of now, there are two ways of writing WebAssembly code in Haskell. The first way is directly manipulating AST types as specified in Asterius.Types . Those types are pretty bare-metal and maps closely to binaryen IR. Simply write some code to generate an AsteriusFunction , and ensure the function and its symbol is present in the store when linking starts. It will eventually be bundled into output WebAssembly binary file. Directly using Asterius.Types is not a pleasant experience, it's basically a DDoS on one's working memory, since the developer needs to keep a lot of things in mind: parameter/local ids, block/loop labels, etc. Also, the resulting Haskell code is pretty verbose, littered with syntactic noise (e.g. tons of list concats when constructing a block) We now provide an EDSL in Asterius.EDSL to construct an AsteriusFunction . Its core type is EDSL a , and can be composed with a Monad or Monoid interface. Most builtin functions in Asterius.Builtins are already refactored to use this EDSL. Typical usages: \"Allocate\" a parameter/local. Use param or local to obtain an immutable Expression which corresponds to the value of a new parameter/local. There are also mutable variants. An opaque LVal type is provided to uniformly deal with local reads/assignments and memory loads/stores. Once an LVal is instantiated, it can be used to read an Expression in the pure world, or set an Expression in the EDSL monad. Several side-effecting instructions can simply be composed with the monadic/monoidal interface, without the need to explicitly construct an anonymous block. When we need named blocks/loops with branching instructions inside, use the block / loop combinators which has the type (Label -> EDSL ()) -> EDSL () . Inside the passed in continuation, we can use break' to perform branching. The Label type is also opaque and cannot be inspected, the only thing we know is that it's scope-checked just like any ordinary Haskell value, so it's impossible to accidently branch to an \"inner\" label. The EDSL only checks for scope safety, so we don't mess up different locals or jump to non-existent labels. Type-safety is not guaranteed (binaryen validator checks for it anyway). Underneath it's just a shallow embedded DSL implemented with a plain old state monad. Some people call it the \"remote monad design pattern\".","title":"Writing WebAssembly code in Haskell"},{"location":"wasm-in-hs/#writing-webassembly-code-in-haskell","text":"In Asterius.Builtins , there are WebAssembly shims which serve as our runtime. We choose to write WebAssembly code in Haskell, using Haskell as our familiar meta-language. As of now, there are two ways of writing WebAssembly code in Haskell. The first way is directly manipulating AST types as specified in Asterius.Types . Those types are pretty bare-metal and maps closely to binaryen IR. Simply write some code to generate an AsteriusFunction , and ensure the function and its symbol is present in the store when linking starts. It will eventually be bundled into output WebAssembly binary file. Directly using Asterius.Types is not a pleasant experience, it's basically a DDoS on one's working memory, since the developer needs to keep a lot of things in mind: parameter/local ids, block/loop labels, etc. Also, the resulting Haskell code is pretty verbose, littered with syntactic noise (e.g. tons of list concats when constructing a block) We now provide an EDSL in Asterius.EDSL to construct an AsteriusFunction . Its core type is EDSL a , and can be composed with a Monad or Monoid interface. Most builtin functions in Asterius.Builtins are already refactored to use this EDSL. Typical usages: \"Allocate\" a parameter/local. Use param or local to obtain an immutable Expression which corresponds to the value of a new parameter/local. There are also mutable variants. An opaque LVal type is provided to uniformly deal with local reads/assignments and memory loads/stores. Once an LVal is instantiated, it can be used to read an Expression in the pure world, or set an Expression in the EDSL monad. Several side-effecting instructions can simply be composed with the monadic/monoidal interface, without the need to explicitly construct an anonymous block. When we need named blocks/loops with branching instructions inside, use the block / loop combinators which has the type (Label -> EDSL ()) -> EDSL () . Inside the passed in continuation, we can use break' to perform branching. The Label type is also opaque and cannot be inspected, the only thing we know is that it's scope-checked just like any ordinary Haskell value, so it's impossible to accidently branch to an \"inner\" label. The EDSL only checks for scope safety, so we don't mess up different locals or jump to non-existent labels. Type-safety is not guaranteed (binaryen validator checks for it anyway). Underneath it's just a shallow embedded DSL implemented with a plain old state monad. Some people call it the \"remote monad design pattern\".","title":"Writing WebAssembly code in Haskell"},{"location":"webassembly/","text":"WebAssembly as a Haskell compilation target There are a few issues to address when compiling Cmm to WebAssembly. Implementing Haskell Stack/Heap The Haskell runtime maintains a TSO(Thread State Object) for each Haskell thread, and each TSO contains a separate stack for the STG machine. The WebAssembly platform has its own \"stack\" concept though; the execution of WebAssembly is based on a stack machine model, where instructions consume operands on the stack and push new values onto it. We use the linear memory to simulate Haskell stack/heap. Popping/pushing the Haskell stack only involves loading/storing on the linear memory. Heap allocation only involves bumping the heap pointer. Running out of space will trigger a WebAssembly trap, instead of doing GC. All discussions in the documentation use the term \"stack\" for the Haskell stack, unless explicitly stated otherwise. Implementing STG machine registers The Haskell runtime makes use of \"virtual registers\" like Sp, Hp or R1 to implement the STG machine. The NCG(Native Code Generator) tries to map some of the virtual registers to real registers when generating assembly code. However, WebAssembly doesn't have language constructs that map to real registers, so we simply implement Cmm local registers as WebAssembly locals, and global registers as fields of StgRegTable . Handling control flow WebAssembly currently enforces structured control flow, which prohibits arbitrary branching. Also, explicit tail calls are missing. The Cmm control flow mainly involves two forms of branching: in-function or cross-function. Each function consists of a map from hoopl labels to basic blocks and an entry label. Branching happens at the end of each basic block. In-function branching is relatively easier to handle. binaryen provides a \"relooper\" which can recover WebAssembly instructions with structured control flow from a control-flow graph. Note that we're using our own relooper though, see issue #22 for relevant discussion. Cross-function branching ( CmmCall ) is tricky. WebAssembly lacks explicit tail calls, and the relooper can't be easily used in this case since there's a computed goto, and potential targets include all Cmm blocks involved in linking. There are multiple possible ways to handle this situation: Collect all Cmm blocks into one function, additionally add a \"dispatcher\" block. All CmmCall s save the callee to a register and branch to the \"dispatcher\" block, and the \"dispatcher\" uses br_table or a binary decision tree to branch to the entry block of callee. One WebAssembly function for one CmmProc , and upon CmmCall the function returns the function id of callee. A mini-interpreter function at the top level repeatedly invoke the functions using call_indirect . This approach is actually used by the unregisterised mode of ghc . We're using the latter approach: every CmmProc marshals to one WebAssembly function. This choice is tightly coupled with some other functionalities (e.g. debug mode) and it'll take quite some effort to switch away. Handling relocations When producing a WebAssembly binary, we need to map CLabel s to the precise linear memory locations for CmmStatics or the precise table ids for CmmProc s. They are unknown when compiling individual modules, so binaryen is invoked only when linking, and during compiling we only convert CLabel s to some serializable representation. Currently WebAssembly community has a proposal for linkable object format, and it's prototyped by lld . We'll probably turn to that format and use lld some day, but right now we'll simply stick to our own format for simplicity. The word size story Although wasm64 is scheduled, currently only wasm32 is implemented. However, we are running 64-bit ghc , and there are several places which need extra care: The load/store instructions operate on 64-bit addresses, yet wasm32 use uint32 when indexing into the linear memory. The CmmSwitch labels are 64-bit. CmmCondBranch also checks a 64-bit condition. br_if / br_table operates on uint32 . Only i32 / i64 is supported by wasm32 value types, but in Cmm we also need arithmetic on 8-bit/16-bit integers. We insert instructions for converting between 32/64-bits in the codegen. The binaryen validator also helps checking bit lengths. As for booleans: there's no native boolean type in either WebAssembly or Cmm. As a convention we use uint32 . Pages and addresses The WebAssembly linear memory has a hard-coded page size of 64KB. There are several places which operate in units of pages rather than raw bytes: CurrentMemory / GrowMemory Memory component of a Module When performing final linking, we layout static data segments to the linear memory. We ensure the memory size is always divisable by MBLOCK_SIZE , so it's easy to allocate new mega blocks and calculate required page count. The first 8 bytes of linear memory (from 0x0 to 0x7) are uninitialized. 0x0 is treated as null pointer, and loading/storing on null pointer or other uninitialized regions is prohibited. In debug mode the program immediately aborts.","title":"WebAssembly as a Haskell compilation target"},{"location":"webassembly/#webassembly-as-a-haskell-compilation-target","text":"There are a few issues to address when compiling Cmm to WebAssembly.","title":"WebAssembly as a Haskell compilation target"},{"location":"webassembly/#implementing-haskell-stackheap","text":"The Haskell runtime maintains a TSO(Thread State Object) for each Haskell thread, and each TSO contains a separate stack for the STG machine. The WebAssembly platform has its own \"stack\" concept though; the execution of WebAssembly is based on a stack machine model, where instructions consume operands on the stack and push new values onto it. We use the linear memory to simulate Haskell stack/heap. Popping/pushing the Haskell stack only involves loading/storing on the linear memory. Heap allocation only involves bumping the heap pointer. Running out of space will trigger a WebAssembly trap, instead of doing GC. All discussions in the documentation use the term \"stack\" for the Haskell stack, unless explicitly stated otherwise.","title":"Implementing Haskell Stack/Heap"},{"location":"webassembly/#implementing-stg-machine-registers","text":"The Haskell runtime makes use of \"virtual registers\" like Sp, Hp or R1 to implement the STG machine. The NCG(Native Code Generator) tries to map some of the virtual registers to real registers when generating assembly code. However, WebAssembly doesn't have language constructs that map to real registers, so we simply implement Cmm local registers as WebAssembly locals, and global registers as fields of StgRegTable .","title":"Implementing STG machine registers"},{"location":"webassembly/#handling-control-flow","text":"WebAssembly currently enforces structured control flow, which prohibits arbitrary branching. Also, explicit tail calls are missing. The Cmm control flow mainly involves two forms of branching: in-function or cross-function. Each function consists of a map from hoopl labels to basic blocks and an entry label. Branching happens at the end of each basic block. In-function branching is relatively easier to handle. binaryen provides a \"relooper\" which can recover WebAssembly instructions with structured control flow from a control-flow graph. Note that we're using our own relooper though, see issue #22 for relevant discussion. Cross-function branching ( CmmCall ) is tricky. WebAssembly lacks explicit tail calls, and the relooper can't be easily used in this case since there's a computed goto, and potential targets include all Cmm blocks involved in linking. There are multiple possible ways to handle this situation: Collect all Cmm blocks into one function, additionally add a \"dispatcher\" block. All CmmCall s save the callee to a register and branch to the \"dispatcher\" block, and the \"dispatcher\" uses br_table or a binary decision tree to branch to the entry block of callee. One WebAssembly function for one CmmProc , and upon CmmCall the function returns the function id of callee. A mini-interpreter function at the top level repeatedly invoke the functions using call_indirect . This approach is actually used by the unregisterised mode of ghc . We're using the latter approach: every CmmProc marshals to one WebAssembly function. This choice is tightly coupled with some other functionalities (e.g. debug mode) and it'll take quite some effort to switch away.","title":"Handling control flow"},{"location":"webassembly/#handling-relocations","text":"When producing a WebAssembly binary, we need to map CLabel s to the precise linear memory locations for CmmStatics or the precise table ids for CmmProc s. They are unknown when compiling individual modules, so binaryen is invoked only when linking, and during compiling we only convert CLabel s to some serializable representation. Currently WebAssembly community has a proposal for linkable object format, and it's prototyped by lld . We'll probably turn to that format and use lld some day, but right now we'll simply stick to our own format for simplicity.","title":"Handling relocations"},{"location":"webassembly/#the-word-size-story","text":"Although wasm64 is scheduled, currently only wasm32 is implemented. However, we are running 64-bit ghc , and there are several places which need extra care: The load/store instructions operate on 64-bit addresses, yet wasm32 use uint32 when indexing into the linear memory. The CmmSwitch labels are 64-bit. CmmCondBranch also checks a 64-bit condition. br_if / br_table operates on uint32 . Only i32 / i64 is supported by wasm32 value types, but in Cmm we also need arithmetic on 8-bit/16-bit integers. We insert instructions for converting between 32/64-bits in the codegen. The binaryen validator also helps checking bit lengths. As for booleans: there's no native boolean type in either WebAssembly or Cmm. As a convention we use uint32 .","title":"The word size story"},{"location":"webassembly/#pages-and-addresses","text":"The WebAssembly linear memory has a hard-coded page size of 64KB. There are several places which operate in units of pages rather than raw bytes: CurrentMemory / GrowMemory Memory component of a Module When performing final linking, we layout static data segments to the linear memory. We ensure the memory size is always divisable by MBLOCK_SIZE , so it's easy to allocate new mega blocks and calculate required page count. The first 8 bytes of linear memory (from 0x0 to 0x7) are uninitialized. 0x0 is treated as null pointer, and loading/storing on null pointer or other uninitialized regions is prohibited. In debug mode the program immediately aborts.","title":"Pages and addresses"}]}